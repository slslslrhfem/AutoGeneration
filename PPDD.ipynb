{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PPDD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1vCXwudXUZpUmzLdlfBoJ0LU7XlCbKpgG",
      "authorship_tag": "ABX9TyNhFvKBZxs/lJpJHIvvUplG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/slslslrhfem/AutoGeneration/blob/master/PPDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxEabHuzyjFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "e6daf9fa-dbc8-4304-875f-fd5a3e9ab4c8"
      },
      "source": [
        "pip install mido"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mido\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/0a/81beb587b1ae832ea6a1901dc7c6faa380e8dd154e0a862f0a9f3d2afab9/mido-1.2.9-py2.py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▎                         | 10kB 31.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 20kB 1.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 30kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 51kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hInstalling collected packages: mido\n",
            "Successfully installed mido-1.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ3x-FF_4XGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "7d6d8745-2544-40a2-eba3-1db5b7555e60"
      },
      "source": [
        "pip install pretty_midi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretty_midi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/8e/63c6e39a7a64623a9cd6aec530070c70827f6f8f40deec938f323d7b1e15/pretty_midi-0.2.9.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pretty_midi) (1.18.5)\n",
            "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.6/dist-packages (from pretty_midi) (1.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pretty_midi) (1.15.0)\n",
            "Building wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-cp36-none-any.whl size=5591953 sha256=acdf7d72c47d1f4f6479778fd848acc6d3e22866f1cdd68b0a9caf542015fcb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/a1/c6/b5697841db1112c6e5866d75a6b6bf1bef73b874782556ba66\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: pretty-midi\n",
            "Successfully installed pretty-midi-0.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kljETrpXyFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "outputId": "cfa78f64-8bb9-4f98-bba6-eb95c99c9684"
      },
      "source": [
        "pip install tensorflow==1.15.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 79.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 68.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (49.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=abf703bb8dcdfeab4c63e46294ed822c2851e0092b7f634c304148cf138b3ede\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP5JOsojTLIE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "e6443880-b5b2-4db3-f715-3f4b7c7020c4"
      },
      "source": [
        "pip install keras==2.3.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 3.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 1.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 1.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.18.5)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upkZgrqruxem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62610a29-bdf1-4025-e736-2112dc766db7"
      },
      "source": [
        "import keras\n",
        "import os\n",
        "import json\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "import pickle\n",
        "import pretty_midi\n",
        "import mido\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import copy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt3ElGb47kOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "56f9b4d9-c2e0-42eb-dbb5-80175c460801"
      },
      "source": [
        "\"\"\"\n",
        "midifilenames=sorted(midifilenames)\n",
        "csvfilenames=sorted(csvfilenames)\n",
        "jsonfilenames=sorted(jsonfilenames)\n",
        "\"\"\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nmidifilenames=sorted(midifilenames)\\ncsvfilenames=sorted(csvfilenames)\\njsonfilenames=sorted(jsonfilenames)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOjmQZTO0TtC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_meta(filename):\n",
        "  with open('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/descriptor/'+filename) as json_file:\n",
        "    meta_data = json.load(json_file)\n",
        "  return meta_data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdprhNM2Y2qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "aec242e1-c194-4e4f-8b8c-703286699fcd"
      },
      "source": [
        "\"\"\"\n",
        "csvfilenames=os.listdir('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_csv')\n",
        "jsonfilenames=os.listdir('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/descriptor')\n",
        "midifilenames=os.listdir('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_midi')\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ncsvfilenames=os.listdir('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_csv')\\njsonfilenames=os.listdir('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/descriptor')\\nmidifilenames=os.listdir('/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_midi')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lpgz0bAYHsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "397f4a0e-befe-4f7b-a225-c22b1694a09d"
      },
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/csvnamelist.txt', 'wb') as f:\n",
        "  pickle.dump(csvfilenames, f)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/jsonnamelist.txt', 'wb') as f:\n",
        "  pickle.dump(jsonfilenames, f)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/midinamelist.txt', 'wb') as f:\n",
        "  pickle.dump(midifilenames, f)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nwith open('/content/drive/My Drive/MARG/PPDDlist/csvnamelist.txt', 'wb') as f:\\n  pickle.dump(csvfilenames, f)\\nwith open('/content/drive/My Drive/MARG/PPDDlist/jsonnamelist.txt', 'wb') as f:\\n  pickle.dump(jsonfilenames, f)\\nwith open('/content/drive/My Drive/MARG/PPDDlist/midinamelist.txt', 'wb') as f:\\n  pickle.dump(midifilenames, f)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoAxt13seNi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/midilist.txt', 'rb') as f:\n",
        "  midilist=pickle.load(f)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/csvlist.txt', 'rb') as f2:\n",
        "  csvlist=pickle.load(f2)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/jsonlist.txt', 'rb') as f3:\n",
        "  jsonlist=pickle.load(f3)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/prettymidilist.txt', 'rb') as f4:\n",
        "  prettymidilist=pickle.load(f4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yc57uuAq2gx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "26c263a9-82b1-4d90-bcc7-33339a2542a3"
      },
      "source": [
        "\"\"\"\n",
        "import pretty_midi\n",
        "import mido\n",
        "from tqdm import tqdm\n",
        "midilist=[]\n",
        "csvlist=[]\n",
        "jsonlist=[]\n",
        "prettymidilist=[]\n",
        "for filenames in tqdm(midifilenames,position=0):\n",
        "  midi_path='/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_midi/'+filenames\n",
        "  mid = mido.MidiFile(midi_path, clip=True)\n",
        "  midilist.append(mid)\n",
        "  prettymid=pretty_midi.PrettyMIDI(midi_path)\n",
        "  prettymidilist.append(prettymid)\n",
        "\n",
        "for filenames in tqdm(csvfilenames,position=0):\n",
        "  csv_path='/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_csv/'+filenames\n",
        "  csv = pandas.read_csv(csv_path)\n",
        "  csvlist.append(csv)\n",
        "for filenames in tqdm(jsonfilenames,position=0):\n",
        "  jsonlist.append(get_meta(filenames))\n",
        "\n",
        "#midifilenames와 list들의 순서는 같다고 생각하고 코드 작성\n",
        "\"\"\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport pretty_midi\\nimport mido\\nfrom tqdm import tqdm\\nmidilist=[]\\ncsvlist=[]\\njsonlist=[]\\nprettymidilist=[]\\nfor filenames in tqdm(midifilenames,position=0):\\n  midi_path='/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_midi/'+filenames\\n  mid = mido.MidiFile(midi_path, clip=True)\\n  midilist.append(mid)\\n  prettymid=pretty_midi.PrettyMIDI(midi_path)\\n  prettymidilist.append(prettymid)\\n\\nfor filenames in tqdm(csvfilenames,position=0):\\n  csv_path='/content/drive/My Drive/MARG/PPDD-Sep2018_sym_mono_large/PPDD-Sep2018_sym_mono_large/prime_csv/'+filenames\\n  csv = pandas.read_csv(csv_path)\\n  csvlist.append(csv)\\nfor filenames in tqdm(jsonfilenames,position=0):\\n  jsonlist.append(get_meta(filenames))\\n\\n#midifilenames와 list들의 순서는 같다고 생각하고 코드 작성\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czIsThWnDhqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e5d2ca5d-1e65-41c7-8937-787f84c4a674"
      },
      "source": [
        "\"\"\"\n",
        "import pickle\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/midilist.txt', 'wb') as f:\n",
        "  pickle.dump(midilist, f)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/csvlist.txt', 'wb') as f:\n",
        "  pickle.dump(csvlist, f)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/jsonlist.txt', 'wb') as f:\n",
        "  pickle.dump(jsonlist, f)\n",
        "with open('/content/drive/My Drive/MARG/PPDDlist/prettymidilist.txt', 'wb') as f:\n",
        "  pickle.dump(prettymidilist, f)\n",
        "\"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nimport pickle\\nwith open('/content/drive/My Drive/MARG/PPDDlist/midilist.txt', 'wb') as f:\\n  pickle.dump(midilist, f)\\nwith open('/content/drive/My Drive/MARG/PPDDlist/csvlist.txt', 'wb') as f:\\n  pickle.dump(csvlist, f)\\nwith open('/content/drive/My Drive/MARG/PPDDlist/jsonlist.txt', 'wb') as f:\\n  pickle.dump(jsonlist, f)\\nwith open('/content/drive/My Drive/MARG/PPDDlist/prettymidilist.txt', 'wb') as f:\\n  pickle.dump(prettymidilist, f)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOttPVfF_yuk",
        "colab_type": "text"
      },
      "source": [
        "아래의 코드는 csv기반의 Processing을 진행한다. \n",
        "MIDI 기반의 Processing은 다음 블록에 작성되어 있으며, 둘 중 하나만 굴리면 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_pieqXw_Yq0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "33b98f60-dd4d-480d-e6d9-b5892fc6e3bd"
      },
      "source": [
        "#현재 CSV dataset에 문제가 있어보인다..\n",
        "\"\"\"\n",
        "bar_list=[]\n",
        "one_bar_number_list=[]\n",
        "starting_number_list=[]\n",
        "import numpy as np\n",
        "for i,csvs in enumerate(tqdm(csvlist)):\n",
        "  a=np.array([list(map(float,csvs.columns))])#column에도 숫자가 들어가 있어서.. 경우에 따라 조절한다\n",
        "  b=np.array(csvs.values)\n",
        "  csvarray=np.concatenate((a,b),axis=0)\n",
        "  if('timeSignature' not in jsonlist[i]):\n",
        "    jsonlist[i]['timeSignature']=[4,4]\n",
        "  one_bar_number=jsonlist[i]['timeSignature'][0]\n",
        "  bar_number=(csvarray[-1][0]-csvarray[0][0])//one_bar_number+1\n",
        "  bar_info_list=[]\n",
        "  for i in range(int(bar_number)):\n",
        "    starting_bar_time=csvarray[0][0]+i*one_bar_number\n",
        "    bar_info_list.append(csvarray[np.where( (starting_bar_time<=csvarray[:,0]) & (csvarray[:,0]<starting_bar_time+one_bar_number) )])\n",
        "  bar_list.append(bar_info_list)\n",
        "  one_bar_number_list.append(one_bar_number)\n",
        "  starting_number_list.append(csvarray[0][0])\n",
        "\"\"\""
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nbar_list=[]\\none_bar_number_list=[]\\nstarting_number_list=[]\\nimport numpy as np\\nfor i,csvs in enumerate(tqdm(csvlist)):\\n  a=np.array([list(map(float,csvs.columns))])#column에도 숫자가 들어가 있어서.. 경우에 따라 조절한다\\n  b=np.array(csvs.values)\\n  csvarray=np.concatenate((a,b),axis=0)\\n  if('timeSignature' not in jsonlist[i]):\\n    jsonlist[i]['timeSignature']=[4,4]\\n  one_bar_number=jsonlist[i]['timeSignature'][0]\\n  bar_number=(csvarray[-1][0]-csvarray[0][0])//one_bar_number+1\\n  bar_info_list=[]\\n  for i in range(int(bar_number)):\\n    starting_bar_time=csvarray[0][0]+i*one_bar_number\\n    bar_info_list.append(csvarray[np.where( (starting_bar_time<=csvarray[:,0]) & (csvarray[:,0]<starting_bar_time+one_bar_number) )])\\n  bar_list.append(bar_info_list)\\n  one_bar_number_list.append(one_bar_number)\\n  starting_number_list.append(csvarray[0][0])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRQyawg_8tO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#이게 이제 input을 midi로 받는 코드.\n",
        "bar_list=[]\n",
        "one_bar_number_list=[]\n",
        "starting_number_list=[]\n",
        "for i,songs in enumerate(prettymidilist):#곡마다.\n",
        "  for instrument in songs.instruments: #2. 어차피 instrument하나\n",
        "    csvarray=[]\n",
        "    for note in instrument.notes: #3\n",
        "      row=[note.start*2, note.pitch, note.pitch, (note.end - note.start)*2, 0] #*2를 해줘야 제대로 하나의 bar가 하나의 단위가 된다.\n",
        "      csvarray.append(row)\n",
        "  csvarray=np.array(csvarray)\n",
        "  if('timeSignature' not in jsonlist[i]):\n",
        "    jsonlist[i]['timeSignature']=[4,4]\n",
        "  one_bar_number=jsonlist[i]['timeSignature'][0]\n",
        "  bar_number=(csvarray[-1][0]-csvarray[0][0])//one_bar_number+1\n",
        "  bar_info_list=[]\n",
        "  for i in range(int(bar_number)):\n",
        "    starting_bar_time=csvarray[0][0]+i*one_bar_number\n",
        "    bar_info_list.append(csvarray[np.where( (starting_bar_time<=csvarray[:,0]) & (csvarray[:,0]<starting_bar_time+one_bar_number) )])\n",
        "  bar_list.append(bar_info_list)# bar info list가 bar마다 csv내용들 담겨져 있는거다.\n",
        "  one_bar_number_list.append(one_bar_number)\n",
        "  starting_number_list.append(csvarray[0][0])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ubPcKmPBXQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d6d87fb4-2acc-4329-c136-b9a1ac92c0a5"
      },
      "source": [
        "\"\"\"\n",
        "for bars in bar_list:\n",
        "  #print(len(bars))결과 보면 다 다르다. 따라서 정해진 Shape가 없음\n",
        "  for matrix in bars:\n",
        "    for lists in matrix:\n",
        "      if (lists[1]<24):\n",
        "        print(lists[1])#Small Data기준 95가 최대, 25가 Minimum. Big Data로 바꾸면 추가적인 조절 가능할듯\n",
        "\"\"\""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor bars in bar_list:\\n  #print(len(bars))결과 보면 다 다르다. 따라서 정해진 Shape가 없음\\n  for matrix in bars:\\n    for lists in matrix:\\n      if (lists[1]<24):\\n        print(lists[1])#Small Data기준 95가 최대, 25가 Minimum. Big Data로 바꾸면 추가적인 조절 가능할듯\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioRp4dJDCtUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4902ea9a-e1bc-4f85-a4f2-7d2e4f4e7f48"
      },
      "source": [
        "print(bar_list[0][0])#1번째 곡의 1번째 bar."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.  48.  48.   0.5  0. ]\n",
            " [ 0.5 55.  55.   0.5  0. ]\n",
            " [ 1.5 52.  52.   0.5  0. ]\n",
            " [ 2.  50.  50.   0.5  0. ]\n",
            " [ 2.5 48.  48.   0.5  0. ]\n",
            " [ 3.  46.  46.   1.   0. ]\n",
            " [ 4.  53.  53.   0.5  0. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK7G2wiA4fgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nearest_time(time,minimum_size):\n",
        "  #혹시나 값이 조금 벗어나는 엇박 음을 가까운 최소단위로 Shifting한다.\n",
        "  #다만 엇박 관련 Skill Detecting을 따로 고려할시 코드를 수정할 수 있다.\n",
        "  num_to_multiply=time/minimum_size\n",
        "  num_to_multiply=int(num_to_multiply)\n",
        "  left_time=num_to_multiply*minimum_size\n",
        "  right_time=left_time+minimum_size\n",
        "  if (time-left_time>=right_time-time):\n",
        "    return right_time\n",
        "  return left_time\n",
        "def bar_to_matrix1(bar,one_bar_number,starting_number,i):\n",
        "  #그냥 점만 남긴다.\n",
        "  #8/6박이면 one_bar_number가 8이다. 그러면 바 1개당 무조건 12개 처리하는거로 한다.\n",
        "  #lists[0]은 시간, lists[1]은 Note 높이, lists[3]은 Duration. \n",
        "  init=np.zeros((112,96))#112는 Note의 수(감으로 써둠.. 나중에 전체 데이터로 할때 수정 가능성 있음 그런데 Shift를 잘 이용하면 96*96도 가능해보임.)\n",
        "  minimum_size=one_bar_number/96\n",
        "  zero_time=starting_number+one_bar_number*i    \n",
        "  for j,lists in enumerate(bar):\n",
        "    \n",
        "    point=int((nearest_time(lists[0],minimum_size)-zero_time)/minimum_size)\n",
        "    if(point==96):\n",
        "      point=92\n",
        "    \n",
        "    init[111-int(lists[1])][point]=lists[3]#111-int(list[1])형태로 해야 직관적인 PianoRoll 형태가 ㅏ온다.\n",
        "  return init\n",
        "def bar_to_matrix2(bar,one_bar_number,starting_number,i):\n",
        "  #Duration에 따라 Ploting한다.\n",
        "  #8/6박이면 one_bar_number가 8이다. 그러면 바 1개당 무조건 12개 처리하는거로 한다.\n",
        "\n",
        "  init=np.zeros((112,96))#112는 Note의 수(감으로 써둠.. 나중에 전체 데이터로 할때 수정 가능성 있음 그런데 Shift를 잘 이용하면 96*96도 가능해보임.)\n",
        "  minimum_size=one_bar_number/96\n",
        "  zero_time=starting_number+one_bar_number*i    \n",
        "  for j,lists in enumerate(bar):\n",
        "    #lists[0]은 시간, lists[1]은 Note 높이, lists[3]은 Duration. \n",
        "    point=int((nearest_time(lists[0],minimum_size)-zero_time)/minimum_size)\n",
        "    length=int(round(lists[3]/minimum_size))\n",
        "    if (length>3):\n",
        "      length=length-1#여러번 두두두 치는 음을 구별하기 위함\n",
        "    if (point+length>95):\n",
        "      length=95-point # 한 음이 2Bar에 걸쳐있는 경우 Bar 뒤쪽의 음을 무시한다.\n",
        "    init[111-int(lists[1])][point:point+length]+=1\n",
        "  return init\n",
        "\n",
        "def bar_to_matrix3(bar,one_bar_number,starting_number,i):\n",
        "  #Duration에 따라 Ploting한다.\n",
        "  #size를 상당히 작게 잡는다.\n",
        "  #8/6박이면 one_bar_number가 8이다. 그러면 바 1개당 무조건 12개 처리하는거로 한다.\n",
        "\n",
        "  init=np.zeros((24,24))#112는 Note의 수(감으로 써둠.. 나중에 전체 데이터로 할때 수정 가능성 있음 그런데 Shift를 잘 이용하면 96*96도 가능해보임.)\n",
        "  minimum_size=one_bar_number/24\n",
        "  zero_time=starting_number+one_bar_number*i\n",
        "  min_height=500\n",
        "  for lists in bar:\n",
        "    if min_height>lists[1]:\n",
        "      min_height=lists[1]    \n",
        "  for j,lists in enumerate(bar):\n",
        "    #lists[0]은 시간, lists[1]은 Note 높이, lists[3]은 Duration. \n",
        "    point=int((nearest_time(lists[0],minimum_size)-zero_time)/minimum_size)\n",
        "    length=int(round(lists[3]/minimum_size))\n",
        "    if (length>3):\n",
        "      length=length-1#여러번 두두두 치는 음을 구별하기 위함\n",
        "    if (point+length>23):\n",
        "      length=23-point # 한 음이 2Bar에 걸쳐있는 경우 Bar 뒤쪽의 음을 무시한다.\n",
        "    height=lists[1]-min_height\n",
        "    while(height>23):\n",
        "      height=height-12\n",
        "    init[23-int(height)][point:point+length]+=1\n",
        "  return init"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t34eVSFIT6M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bar_list to bar_matrix_list\n",
        "#bar_matrix_list=copy.deepcopy(bar_list)\n",
        "#bar_matrix_list2=copy.deepcopy(bar_list)\n",
        "bar_matrix_list3=copy.deepcopy(bar_list)\n",
        "for i,songs in enumerate(bar_matrix_list3):\n",
        "  for j,bar in enumerate(songs):\n",
        "    #print(one_bar_number_list[i],starting_number_list[i])\n",
        "    #matrix=bar_to_matrix1(bar,one_bar_number_list[i],starting_number_list[i],j)\n",
        "    #matrix2=bar_to_matrix2(bar,one_bar_number_list[i],starting_number_list[i],j)\n",
        "    matrix3=bar_to_matrix3(bar,one_bar_number_list[i],starting_number_list[i],j)\n",
        "    #bar_matrix_list[i][j]=matrix\n",
        "    #bar_matrix_list2[i][j]=matrix2\n",
        "    bar_matrix_list3[i][j]=matrix3"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJUSzyDlbQ3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bar_updown_list=copy.deepcopy(bar_list)\n",
        "for i,songs in enumerate(bar_list):\n",
        "  for j,bar in enumerate(songs):\n",
        "    if (j==len(songs)-1):\n",
        "      updown_label='final'\n",
        "    elif(len(bar_list[i][j])==0 or len(bar_list[i][j+1])==0):\n",
        "      updown_label='meanless'\n",
        "    else:\n",
        "      if(bar_list[i][j][len(bar_list[i][j])-1][1]<=bar_list[i][j+1][0][1]):\n",
        "        updown_label='up'\n",
        "      else:\n",
        "        updown_label='down'\n",
        "    bar_updown_list[i][j]=updown_label"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO6-SYCu29qF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c395275b-0003-43ec-f435-871128743621"
      },
      "source": [
        "#print(bar_list[0][0],bar_matrix_list[0][0],bar_matrix_list2[0][0]) 큰 의미 없다\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "H = bar_matrix_list3[0][0]\n",
        "\n",
        "fig = plt.figure(figsize=(6, 3.2))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title('colorMap')\n",
        "plt.imshow(H)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
        "cax.get_xaxis().set_visible(False)\n",
        "cax.get_yaxis().set_visible(False)\n",
        "cax.patch.set_alpha(0)\n",
        "cax.set_frame_on(False)\n",
        "plt.colorbar(orientation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x230.4 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV-em-Jo4I8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "aad7f483-257b-4972-ace8-4d73a43cfe0a"
      },
      "source": [
        "tot=bar_matrix_list3[2]\n",
        "H=bar_matrix_list3[2][0]\n",
        "for i in range(1,len(tot)):\n",
        "  a=bar_matrix_list3[2][i]\n",
        "  H=np.concatenate((H,a),axis=1)\n",
        "  \n",
        "fig = plt.figure(figsize=(30, 3.2))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title('colorMap')\n",
        "plt.imshow(H)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
        "cax.get_xaxis().set_visible(False)\n",
        "cax.get_yaxis().set_visible(False)\n",
        "cax.patch.set_alpha(0)\n",
        "cax.set_frame_on(False)\n",
        "plt.colorbar(orientation='vertical')\n",
        "plt.show()\n",
        "#위 for문 없이 돌리면 1 bar만 나옴"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2160x230.4 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhslYmbJdSba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bar_to_contour(bar,one_bar_number,starting_number,j):\n",
        "  contour=[]\n",
        "  pitch_change_list=[]\n",
        "  duration_list=[]\n",
        "  real_pitch_list=[]\n",
        "  real_time_list=[]\n",
        "  real_duration_list=[]\n",
        "  now_pitch=1000\n",
        "  first_time=starting_number+one_bar_number*j\n",
        "  a=0\n",
        "  for lists in bar:\n",
        "    if(a!=0): \n",
        "      real_time_list.append(lists[0]-now_rhythm)\n",
        "    now_rhythm=lists[0]\n",
        "    a+=1\n",
        "    if (first_time*1.001<lists[0]):#smoothing for case like first time=5.00001, lists[0]=5.0000..\n",
        "      resting_time=lists[0]-first_time\n",
        "      duration_list.append(resting_time)\n",
        "      first_time=lists[0]\n",
        "      pitch_change_list.append('Rest')\n",
        "    if (now_pitch==1000):\n",
        "      pitch_change_list.append('Starting_Point')\n",
        "      real_pitch_list.append('Starting_Point')\n",
        "      real_duration_list.append(lists[3])\n",
        "      duration_list.append(lists[3])\n",
        "      first_time=first_time+lists[3]\n",
        "      now_pitch=lists[1]\n",
        "      a+=1\n",
        "    else:\n",
        "      pitch_change=lists[1]-now_pitch\n",
        "      pitch_change_list.append(str(pitch_change))#나중에 int로 바꿔쓸 것. 자료형 터지는거 때문에 우선 스트링.\n",
        "      duration_list.append(lists[3])\n",
        "      real_duration_list.append(lists[3])\n",
        "      first_time=first_time+lists[3]\n",
        "      now_pitch=lists[1]\n",
        "      real_pitch_list.append(str(pitch_change))\n",
        "  if (first_time*1.001<starting_number+one_bar_number*(j+1)):\n",
        "    pitch_change_list.append('Rest')#마지막 Rest\n",
        "    duration_list.append(starting_number+one_bar_number*(j+1)-first_time)\n",
        "  if(len(bar)!=0):\n",
        "    real_time_list.append(starting_number+one_bar_number*(j+1)-now_rhythm)\n",
        "  contour.append(pitch_change_list)\n",
        "  contour.append(duration_list)\n",
        "  contour.append(real_pitch_list)\n",
        "  contour.append(real_time_list)\n",
        "  contour.append(real_duration_list)\n",
        "  #something\n",
        "  return contour\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkt16alDXVFp",
        "colab_type": "text"
      },
      "source": [
        "Plot에서 중요한것은 Y-Axis의 0~112의 숫자가 Note의 반대 성향을 가진다는 것이다.(숫자가 커질수록 Note의 높이가 낮아진다.) 이는 PianoRoll을 이미지 처럼 사용하는 과정에서, 직관적인 학습이 가능하도록 이와 같이 구현한 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DB6np0r4pr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bar_contour_list=copy.deepcopy(bar_list)\n",
        "for i,songs in enumerate(bar_list):\n",
        "  for j,bar in enumerate(songs):\n",
        "    contour=bar_to_contour(bar,one_bar_number_list[i],starting_number_list[i],j)\n",
        "    bar_contour_list[i][j]=contour\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFxmPmNCVpBD",
        "colab_type": "text"
      },
      "source": [
        "bar_contour_list : 중간과정\n",
        "bar_matrix_list2 : 아마 학습에 사용하게 될 Matrix의 List\n",
        "bar_label_list : 학습에 사용하게 될 Label의 List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO49MM20Lth1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5b0d597e-1c8f-402b-87a2-9478609de3c1"
      },
      "source": [
        "print(bar_contour_list[0][0])\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Starting_Point', '7.0', 'Rest', '-3.0', '-2.0', '-2.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '7.0', '-3.0', '-2.0', '-2.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqJXy8Wqv1od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "89244596-fb6b-4757-ec67-f5b9bbadc565"
      },
      "source": [
        "for contours in bar_contour_list[11]:\n",
        "  print(contours)\n",
        "print(jsonlist[11])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Starting_Point', 'Rest', '-8.0', '3.0', 'Rest', '5.0', 'Rest'], [0.3333333333333333, 0.16666666666666669, 0.25, 0.16666666666666663, 0.08333333333333337, 0.33333333333333326, 2.666666666666667], ['Starting_Point', '-8.0', '3.0', '5.0'], [0.5, 0.25, 0.25, 3.0], [0.3333333333333333, 0.25, 0.16666666666666663, 0.33333333333333326]]\n",
            "[['Rest', 'Starting_Point', '1.0'], [3.5, 0.25, 0.33333333333333215], ['Starting_Point', '1.0'], [0.25, 0.25], [0.25, 0.33333333333333215]]\n",
            "[['Starting_Point', 'Rest'], [0.25, 3.75], ['Starting_Point'], [4.0], [0.25]]\n",
            "[['Rest'], [4.0], [], [], []]\n",
            "[['Starting_Point', '-9.0', '1.0', '8.0', '-12.0', 'Rest'], [0.25, 0.25, 0.33333333333333215, 0.25, 0.33333333333333215, 2.5833333333333357], ['Starting_Point', '-9.0', '1.0', '8.0', '-12.0'], [0.25, 0.25, 0.25, 0.25, 3.0], [0.25, 0.25, 0.33333333333333215, 0.25, 0.33333333333333215]]\n",
            "[['Rest'], [4.0], [], [], []]\n",
            "[['Starting_Point', '-9.0', '1.0', '3.0', 'Rest', '5.0', 'Rest'], [0.25, 0.25, 0.25, 0.1666666666666643, 0.0833333333333357, 0.25, 2.75], ['Starting_Point', '-9.0', '1.0', '3.0', '5.0'], [0.25, 0.25, 0.25, 0.25, 3.0], [0.25, 0.25, 0.25, 0.1666666666666643, 0.25]]\n",
            "[['Rest', 'Starting_Point', 'Rest', '-3.0', 'Rest'], [3.0, 0.25, 0.25, 0.1666666666666643, 0.3333333333333357], ['Starting_Point', '-3.0'], [0.5, 0.5], [0.25, 0.1666666666666643]]\n",
            "[['Starting_Point', 'Rest', '2.0', 'Rest'], [0.1666666666666643, 0.0833333333333357, 0.75, 3.0], ['Starting_Point', '2.0'], [0.25, 3.75], [0.1666666666666643, 0.75]]\n",
            "[['Rest'], [4.0], [], [], []]\n",
            "[['Starting_Point', '1.0', '8.0', 'Rest'], [0.25, 0.25, 0.25, 3.25], ['Starting_Point', '1.0', '8.0'], [0.25, 0.25, 3.5], [0.25, 0.25, 0.25]]\n",
            "[['Rest'], [4.0], [], [], []]\n",
            "[['Starting_Point', 'Rest', '-8.0', '8.0', '-9.0', '1.0', '8.0', '-9.0', '1.0', '8.0', '-9.0', '1.0', '8.0', '-8.0', '8.0'], [0.3333333333333286, 0.1666666666666714, 0.3333333333333286, 0.3333333333333286, 0.25, 0.3333333333333286, 0.3333333333333286, 0.25, 0.25, 0.25, 0.25, 0.25, 0.3333333333333286, 0.3333333333333286, 0.25], ['Starting_Point', '-8.0', '8.0', '-9.0', '1.0', '8.0', '-9.0', '1.0', '8.0', '-9.0', '1.0', '8.0', '-8.0', '8.0'], [0.5, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.25, 0.25], [0.3333333333333286, 0.3333333333333286, 0.3333333333333286, 0.25, 0.3333333333333286, 0.3333333333333286, 0.25, 0.25, 0.25, 0.25, 0.25, 0.3333333333333286, 0.3333333333333286, 0.25]]\n",
            "[['Starting_Point', 'Rest', '12.0', 'Rest', '0.0', 'Rest', '-3.0', 'Rest'], [0.25, 2.75, 0.1666666666666643, 0.0833333333333357, 0.1666666666666643, 0.0833333333333357, 0.1666666666666643, 0.3333333333333357], ['Starting_Point', '12.0', '0.0', '-3.0'], [3.0, 0.25, 0.25, 0.5], [0.25, 0.1666666666666643, 0.1666666666666643, 0.1666666666666643]]\n",
            "[['Starting_Point', 'Rest'], [0.1666666666666643, 3.8333333333333357], ['Starting_Point'], [4.0], [0.1666666666666643]]\n",
            "{'id': '00218695-5fc3-47eb-871f-16f0955840ae', 'idLakh': 'aca4cae9b1320fa31141492ed99c3bc0', 'bpm': 110, 'timeSignature': [4, 4], 'keyEstimate': 'A major'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MThJLfY0V6F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#최대한 많고 깔끔한 조건문을 사용하여 Skill들을 정의해볼 것. Multilabel Classification의 가능성이 있다.\n",
        "\"\"\"\n",
        "Skill들의 음악학적인 특성 & 계산적인 특성을 적는 곳\n",
        "'resting' : 포함하는 음이 0 또는 1개인 경우 resting으로 정의. 다른 Skill들은 겹칠 수 있으나 이 skill이 Label될 경우 그냥 resting 고정이다.\n",
        "즉, Skilling Labeling은 'resting'이 아닌 경우에 진행된다.\n",
        "'repeating' : 전체 음 중 n% 이상 또는 n개를 제외한 경우가 전부 같은 음일 경우 repeating으로 정의\n",
        "'up_steping' : 전체 음 중 n% 이상 또는 n개를 제외한 경우가 steping up 또는 같은 음, 즉 반음기준 3Note 이하로 상승하는 형태일 경우 up_steping으로 정의\n",
        "'down_steping' : 전체 음 중 n% 이상 또는 n개를 제외한 경우가 steping down 또는 같은 음, 즉 반음기준 3Note 이하로 하강하는 형태일 경우 down_steping으로 정의\n",
        "'up_leaping' : 전체 음 중 n% 이상 또는 n개를 제외한 경우가 leaping up, 즉 반음기준 3Note 이상으로 상승하는 형태일 경우 up_leaping으로 정의\n",
        "'down_leaping' : 전체 음 중 n% 이상 또는 n개를 제외한 경우가 leaping down, 즉 반음기준 3Note 이상으로 하강하는 형태일 경우 down_leaping으로 정의\n",
        "3Note에서 겹치는게 맞다. Multilabel Classification을 고안 중이기 때문.\n",
        "'steping_twisting' : 음이 4개 이상이고, n개를 제외한 경우가 2Note 이하의 상승과 하강을 반복하는 형태일 경우 steping_twisting으로 정의\n",
        "'leaping_twisting' : 음이 4개 이상이고, n개를 제외한 경우가 3Note 이상의 상승과 하강을 반복하는 형태일 경우 leaping_twisting으로 정의\n",
        "'fast_rhythm' : 1 bar 내에 음이 9개 이상인 경우 fast_rhythm으로 정의.\n",
        "'One_rhythm' :  모든 음이 지닌 연주의 real_time, 즉 음이 울리고 다음 음이 나올때 까지의 시간이 같으면 One_rhythm으로 정의\n",
        "'triplet' : real_time기반해서 triplet이 존재하면(Note 3개) triplet으로 정의\n",
        "'Staccato' : real_Duration_Time 기반해서 n% 이상의 음의 Duration이 0.16667(최소단위*4임)보다 작으면(매우 짧으면) Staccato로 정의\n",
        "'continuing_rhythm' : pitch_change_list에서 'Rest'의 비율이 25퍼센트 이하면 continuing_rhythm으로 정의\n",
        "첫 음 제외 실 음의 75%를 기준으로 잡는다.\n",
        "5개 이상의 음이 있다면 1개를 제외하고 전부 조건에 맞아야하고,\n",
        "9개 이상의 음이 있다면 2개를 제외하고 전부 조건에 맞아야하고...\n",
        "4개 이하는 다 맞아야 한다.\n",
        "ex) CDEF -> up_steping, CDED -> None, CDEFD-> up_steping.\n",
        "다만 Leaping에 대해서는 많이 후해질 것 같다. 거의 50%가까이..?  \n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "예시로는..\n",
        "contour[0] = ['Starting_Point', 'Rest', '4.0', '1.0', 'Rest', '2.0', 'Rest', '-7.0', 'Rest'] Note pitch의 변화를 쉼표를 포함하여 의미한다.\n",
        "contour[1] = [0.83333, 0.16666999999999987, 0.5, 0.33333, 0.16666999999999987, 0.8333299999999999, 0.16666999999999987, 0.75, 0.25] Duration을 쉼표를 포함하여 의미한다.\n",
        "contour[2] = ['Starting_Point', '4.0', '1.0', '2.0', '-7.0'] note pitch의 변화를 의미한다.\n",
        "contour[3] = [1.0, 0.5, 0.5, 1.0, 1.0] 한 음의 실 연주시간을 의미한다.(다음 음이 나올때 까지의 시간)\n",
        "contour[4] = [0.83333, 0.5, 0.33333, 0.8333299999999999, 0.75] Duration을 의미한다.\n",
        "\"\"\"\n",
        "def is_repeating(contour_list,exception_range):\n",
        "  boolean_repeating=0\n",
        "  non_repeat=0\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if(elements != '0.0'):\n",
        "        non_repeat+=1\n",
        "  if (non_repeat<=exception_range):\n",
        "    boolean_repeating=1\n",
        "  return boolean_repeating\n",
        "\n",
        "def is_up_steping(contour_list,exception_range):\n",
        "  balancing_param=1\n",
        "  boolean_up_steping=0\n",
        "  non_step_up=0\n",
        "  now_step_up=0\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if (now_step_up==0):\n",
        "        if (float(elements)<0.5 or float(elements)>4.5):\n",
        "          now_step_up=0\n",
        "          non_step_up+=1\n",
        "        else:\n",
        "          now_step_up=1\n",
        "      else:\n",
        "        if(float(elements)<-0.5 or float(elements)>4.5):\n",
        "          now_step_up=0\n",
        "          non_step_up+=1\n",
        "        else:\n",
        "          now_step_up=1\n",
        "  if(non_step_up<=exception_range+balancing_param):\n",
        "    boolean_up_steping=1\n",
        "  return boolean_up_steping\n",
        "\n",
        "def is_down_steping(contour_list,exception_range):\n",
        "  boolean_down_steping=0\n",
        "  balancing_param=0\n",
        "  non_step_down=0\n",
        "  now_step_down=0\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if (now_step_down==0):\n",
        "        if (float(elements)>-0.5 or float(elements)<-4.5):\n",
        "          now_step_down=0\n",
        "          non_step_down+=1\n",
        "        else:\n",
        "          now_step_down=1\n",
        "      else:\n",
        "        if(float(elements)>0.5 or float(elements)<-4.5):\n",
        "          now_step_down=0\n",
        "          non_step_down+=1\n",
        "        else:\n",
        "          now_step_down=1\n",
        "  if(non_step_down<=exception_range+balancing_param):\n",
        "    boolean_down_steping=1\n",
        "  return boolean_down_steping\n",
        "\n",
        "def is_up_leaping(contour_list,exception_range):\n",
        "  boolean_up_leaping=0\n",
        "  non_leap_up=0\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if (float(elements)<3.5):\n",
        "        non_leap_up+=1\n",
        "  if (non_leap_up<=exception_range+1):\n",
        "    boolean_up_leaping=1\n",
        "  return boolean_up_leaping\n",
        "\n",
        "def is_down_leaping(contour_list,exception_range):\n",
        "  boolean_down_leaping=0\n",
        "  non_leap_down=0\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if (float(elements)>-3.5):\n",
        "        non_leap_down+=1\n",
        "  if (non_leap_down<=exception_range+1):\n",
        "    boolean_down_leaping=1\n",
        "  return boolean_down_leaping\n",
        "\n",
        "def is_leaping_twisting(contour_list,exception_range):\n",
        "  boolean_leaping_twisting=0\n",
        "  non_leap_twist=0\n",
        "  balancing_param=1\n",
        "  now_dir=0 #1for up, -1 for down\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if (now_dir==0):\n",
        "        if (3.5<float(elements)):\n",
        "          now_dir=1\n",
        "        elif (float(elements) <-3.5):\n",
        "          now_dir=-1\n",
        "        else:\n",
        "          non_leap_twist+=1\n",
        "      elif (now_dir==1):\n",
        "        if (float(elements) <-3.5):\n",
        "          now_dir=-1\n",
        "        else:\n",
        "          now_dir=0\n",
        "          non_leap_twist+=1\n",
        "      elif (now_dir==-1):\n",
        "        if (3.5<float(elements)):\n",
        "          now_dir=1\n",
        "        else:\n",
        "          now_dir=0\n",
        "          non_leap_twist+=1\n",
        "  if(non_leap_twist<=exception_range+balancing_param):\n",
        "    boolean_leaping_twisting=1\n",
        "  return boolean_leaping_twisting\n",
        "\n",
        "def is_steping_twisting(contour_list,exception_range):\n",
        "  boolean_steping_twisting=0\n",
        "  non_step_twist=0\n",
        "  now_dir=0 #1for up, -1 for down\n",
        "  for elements in contour_list:\n",
        "    if (elements is not 'Starting_Point'):\n",
        "      if (now_dir==0):\n",
        "        if (0<float(elements) and float(elements) <2.5):\n",
        "          now_dir=1\n",
        "        elif (-2.5<float(elements) and float(elements) <0):\n",
        "          now_dir=-1\n",
        "        else:\n",
        "          non_step_twist+=1\n",
        "      elif (now_dir==1):\n",
        "        if (-2.5<float(elements) and float(elements) <0):\n",
        "          now_dir=-1\n",
        "        else:\n",
        "          now_dir=0\n",
        "          non_step_twist+=1\n",
        "      elif (now_dir==-1):\n",
        "        if (0<float(elements) and float(elements) <2.5):\n",
        "          now_dir=1\n",
        "        else:\n",
        "          now_dir=0\n",
        "          non_step_twist+=1\n",
        "  if(non_step_twist<=exception_range):\n",
        "    boolean_steping_twisting=1\n",
        "  return boolean_steping_twisting\n",
        "\n",
        "def is_one_rhythm(contour_list,exception_range):\n",
        "  boolean_one_rhythm=0\n",
        "  non_same_rhythm=0\n",
        "\n",
        "  first_rhythm=contour_list[0]\n",
        "  for rhythms in contour_list:\n",
        "    if (rhythms != first_rhythm):\n",
        "      non_same_rhythm=1\n",
        "  boolean_one_rhythm=1-non_same_rhythm\n",
        "  return boolean_one_rhythm\n",
        "\n",
        "def is_triplet(contour_list,exception_range):\n",
        "  boolean_triplet=0\n",
        "  now_triplet=0\n",
        "  for rhythms in contour_list:\n",
        "    rhythms=float(rhythms)\n",
        "    if (rhythms%0.015625>0.001):\n",
        "      if(now_triplet==1):\n",
        "        boolean_triplet=1\n",
        "      now_triplet+=1\n",
        "    else:\n",
        "      now_triplet=0\n",
        "      \n",
        "  return boolean_triplet\n",
        "\n",
        "def is_staccato(contour_list,exception_range):\n",
        "  boolean_staccato=0\n",
        "  ranges=len(contour_list)//2\n",
        "  staccato_num=0\n",
        "  for times in contour_list:\n",
        "    if (times<0.2):\n",
        "      staccato_num+=1\n",
        "  if (staccato_num>=ranges):\n",
        "    boolean_staccato=1\n",
        "  return boolean_staccato\n",
        "\n",
        "def is_continuing_rhythm(contour_list):\n",
        "  boolean_continuing_rhythm=0\n",
        "  length=len(contour_list)\n",
        "  rest_num=0\n",
        "  for elements in contour_list:\n",
        "    if (elements=='Rest'):\n",
        "      rest_num+=1\n",
        "  if (rest_num<=0.5):\n",
        "    boolean_continuing_rhythm=1\n",
        "  return boolean_continuing_rhythm\n",
        "\n",
        "def contour_to_label(contour):\n",
        "  labels=[]\n",
        "  totnum=len(contour[2]) #실 음의 갯수이다.\n",
        "  exception_range=(totnum-1)//4\n",
        "  exception_range2=(totnum-1)//3\n",
        "  if (len(contour[2])<2.5):\n",
        "    labels.append('resting')\n",
        "    return labels\n",
        "  else:\n",
        "    if (is_repeating(contour[2],exception_range2)):\n",
        "      labels.append('repeating')\n",
        "\n",
        "    if (is_up_steping(contour[2],exception_range)):\n",
        "      if (len(contour[2])>3):\n",
        "        labels.append('up_steping')\n",
        "\n",
        "    if (is_down_steping(contour[2],exception_range)):\n",
        "      if (len(contour[2])>3):\n",
        "        labels.append('down_steping')\n",
        "\n",
        "    if (is_up_leaping(contour[2],exception_range2)):\n",
        "      labels.append('up_leaping')\n",
        "    \n",
        "    if (is_down_leaping(contour[2],exception_range2)):\n",
        "      labels.append('down_leaping')\n",
        "\n",
        "    if (is_steping_twisting(contour[2],exception_range2)):\n",
        "      if (len(contour[2])>3):\n",
        "        labels.append('steping_twisting')\n",
        "\n",
        "    if (is_leaping_twisting(contour[2],exception_range2)):\n",
        "      if (len(contour[2])>3):\n",
        "        labels.append('leaping_twisting')\n",
        "\n",
        "    if (len(contour[2])>8.5):\n",
        "      labels.append('fast_rhythm')\n",
        "\n",
        "    if (is_one_rhythm(contour[3],exception_range)):\n",
        "      labels.append('One_rhythm')\n",
        "\n",
        "    if (is_triplet(contour[3],exception_range2)):\n",
        "      labels.append('triplet')\n",
        "\n",
        "    if (is_staccato(contour[4],exception_range2)):\n",
        "      labels.append('staccato')  \n",
        "\n",
        "    if (is_continuing_rhythm(contour[0])):\n",
        "      labels.append('continuing_rhythm')  \n",
        "\n",
        "  \"\"\"\n",
        "  if (len(labels)==0):\n",
        "    labels.append('no skills')\n",
        "    meanless.\n",
        "  \"\"\"\n",
        "\n",
        "  return labels"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez9WMZruqLA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bar_label_list=copy.deepcopy(bar_contour_list)\n",
        "for i,songs in enumerate(bar_contour_list):\n",
        "  for j,contour in enumerate(songs):\n",
        "    label=contour_to_label(contour) \n",
        "    bar_label_list[i][j]=label"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqUWmjlproso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "db10e71c-4dfb-4f58-f96f-15458f73aca5"
      },
      "source": [
        "for j in range(len(bar_label_list[0])):\n",
        "  print(bar_label_list[0][j])\n",
        "  print(bar_contour_list[0][j])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[['Starting_Point', '7.0', 'Rest', '-3.0', '-2.0', '-2.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '7.0', '-3.0', '-2.0', '-2.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "[]\n",
            "[['Starting_Point', '7.0', 'Rest', '-3.0', '-2.0', '-2.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '7.0', '-3.0', '-2.0', '-2.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "['repeating']\n",
            "[['Starting_Point', '7.0', 'Rest', '-7.0', '0.0', '0.0', '0.0', '0.0'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0], ['Starting_Point', '7.0', '-7.0', '0.0', '0.0', '0.0', '0.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0]]\n",
            "['leaping_twisting', 'continuing_rhythm']\n",
            "[['Starting_Point', '7.0', '-7.0', '4.0', '3.0', '3.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], ['Starting_Point', '7.0', '-7.0', '4.0', '3.0', '3.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '7.0', '-7.0', '7.0', '3.0', '-5.0', 'Rest'], [0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5], ['Starting_Point', '7.0', '-7.0', '7.0', '3.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 1.0, 1.5], [0.5, 1.0, 0.5, 0.5, 1.0, 1.0]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '7.0', '-7.0', '7.0', '3.0', '-5.0', 'Rest'], [0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5], ['Starting_Point', '7.0', '-7.0', '7.0', '3.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 1.0, 1.5], [0.5, 1.0, 0.5, 0.5, 1.0, 1.0]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '7.0', '-7.0', '7.0', '3.0', '-5.0', 'Rest'], [0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5], ['Starting_Point', '7.0', '-7.0', '7.0', '3.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 1.0, 1.5], [0.5, 1.0, 0.5, 0.5, 1.0, 1.0]]\n",
            "[]\n",
            "[['Starting_Point', '0.0', 'Rest', '-5.0', '5.0', '-2.0', '-1.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5], ['Starting_Point', '0.0', '-5.0', '5.0', '-2.0', '-1.0'], [0.5, 1.0, 0.5, 1.0, 1.0, 1.0], [0.5, 0.5, 0.5, 1.0, 1.0, 0.5]]\n",
            "[]\n",
            "[['Starting_Point', '0.0', 'Rest', '-5.0', '5.0', '-2.0', '-1.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5], ['Starting_Point', '0.0', '-5.0', '5.0', '-2.0', '-1.0'], [0.5, 1.0, 0.5, 1.0, 1.0, 1.0], [0.5, 0.5, 0.5, 1.0, 1.0, 0.5]]\n",
            "[]\n",
            "[['Starting_Point', '0.0', 'Rest', '-5.0', '5.0', '-2.0', '-1.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5], ['Starting_Point', '0.0', '-5.0', '5.0', '-2.0', '-1.0'], [0.5, 1.0, 0.5, 1.0, 1.0, 1.0], [0.5, 0.5, 0.5, 1.0, 1.0, 0.5]]\n",
            "[]\n",
            "[['Starting_Point', '0.0', 'Rest', '-5.0', '5.0', '0.0', 'Rest', '0.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5], ['Starting_Point', '0.0', '-5.0', '5.0', '0.0', '0.0'], [0.5, 1.0, 0.5, 1.0, 1.0, 1.0], [0.5, 0.5, 0.5, 1.0, 0.5, 0.5]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '-5.0', 'Rest', '-7.0', '3.0', '4.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '-5.0', '-7.0', '3.0', '4.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '-5.0', 'Rest', '-7.0', '3.0', '4.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '-5.0', '-7.0', '3.0', '4.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '-5.0', 'Rest', '-7.0', '3.0', '4.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '-5.0', '-7.0', '3.0', '4.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '-5.0', 'Rest', '-7.0', '3.0', '4.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '-5.0', '-7.0', '3.0', '4.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "['leaping_twisting']\n",
            "[['Starting_Point', '0.0', 'Rest', '0.0', '7.0', '-7.0', '10.0', '-5.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '0.0', '0.0', '7.0', '-7.0', '10.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "['down_leaping', 'leaping_twisting']\n",
            "[['Starting_Point', '-5.0', 'Rest', '-7.0', '3.0', '4.0', '5.0', '-5.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '-5.0', '-7.0', '3.0', '4.0', '5.0', '-5.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eCyCmgXzbSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "2631a5fa-0c32-46ee-f12e-53714dcf3f11"
      },
      "source": [
        "#Summary\n",
        "print(bar_contour_list[0][0])\n",
        "print(bar_label_list[0][0])\n",
        "print(bar_list[0][0])\n",
        "\n",
        "H=bar_matrix_list3[0][0]\n",
        "fig = plt.figure(figsize=(6, 3.2))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title('colorMap')\n",
        "plt.imshow(H)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
        "cax.get_xaxis().set_visible(False)\n",
        "cax.get_yaxis().set_visible(False)\n",
        "cax.patch.set_alpha(0)\n",
        "cax.set_frame_on(False)\n",
        "plt.colorbar(orientation='vertical')\n",
        "plt.show()\n",
        "#위 for문 없이 돌리면 1 bar만 나옴\n",
        "#matrix_list2를 CNN하되 라벨을 label로 가져가면 될듯 bar_label_list[i][j]는 i번째곡의 j번째 bar를 의미하고, 나머지도 같다."
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Starting_Point', '7.0', 'Rest', '-3.0', '-2.0', '-2.0', '-2.0', '7.0', 'Rest'], [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5], ['Starting_Point', '7.0', '-3.0', '-2.0', '-2.0', '-2.0', '7.0'], [0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0], [0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5]]\n",
            "[]\n",
            "[[ 0.  48.  48.   0.5  0. ]\n",
            " [ 0.5 55.  55.   0.5  0. ]\n",
            " [ 1.5 52.  52.   0.5  0. ]\n",
            " [ 2.  50.  50.   0.5  0. ]\n",
            " [ 2.5 48.  48.   0.5  0. ]\n",
            " [ 3.  46.  46.   1.   0. ]\n",
            " [ 4.  53.  53.   0.5  0. ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAADdCAYAAADQI0sNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUMklEQVR4nO3de5BedX3H8feHEEi5eMFoCiQIanAa0YKTAWdwNBQvgbFEp5YSa4GWIf5BrBfqiNQCQ0fFtqI4UssKKReVS1EkY1OjUBlqq5hYHSRQNEUiCYEQiJKKQLL76R/nrD552D3P2d3sc052P6+ZM3suv+d3vjzAd3+3c1a2iYiI3vZqOoCIiD1FEmZERE1JmBERNSVhRkTUlIQZEVFTEmZERE1JmNEakg6XZEl7Nx1LxEiSMGPKkHRRmXDf13X+feX5ixoKLaaIJMyYEjpapT8BTu+6fEZ5PmJCkjBj0kiaJ+mrkh6T9Likz0naS9JHJW2QtEXStZKeP8rnD5G0UtITktZLOrvj2kWSbpb0RUlPAmeWl9YA+0l6VVnuVcCs8vzwZ18o6etlXNvK/bkd1++Q9AlJ35f0pKRbJR20+7+h2NMkYcakkDQD+DqwATgcOBS4gSKxnQmcALwMOAD43CjV3ABsBA4B3gl8XNIfdFxfAtwMvAD4Usf56/htK/OM8rjTXsA/Ay8FDgN+PUIMpwN/ARwM7AQ+W/XPG9NDEmZMlmMpEt2HbP/K9tO2vwP8KXCp7Qds/x/wEeC07okeSfOA44EPl5/9EXAlu3a3v2v7a7aHbP+64/wXgaWSZgKnlce/Yftx21+x/ZTt7cDHgDd2xX+d7Xts/wr4G+DU8pdATGNJmDFZ5gEbbO/sOn8IRatz2AZgb2DOCOWeKBNaZ9lDO44fGunGtn8OrAc+DvzU9i7lJO0n6YpyWOBJ4E7gBV0JsfMzG4CZwOyR7hfTRxJmTJaHgMNGWCL0MEVXeNhhFF3eR0cod5CkA7vKbuo4rnrV1rXAueXPbucCrwSOs/084A3leXWUmdd13x3A1or7xTSQhBmT5fvAZuASSftLmiXpeOB64AOSjpB0AEUr8MbulmjZKvwv4BPlZ18DnEVX97rCjcBbgJtGuHYgxbjlL8rJnAtHKPNuSQsk7QdcDNxse7DmvaMFJK0oJxbvGeW6JH22nFC8W9Jre9WZhBmTokwufwi8Avg5xeTNnwArKCZh7gR+BjwNvHeUapZSTBg9DNwCXGj7tpr3/7Xt27rGNod9Bvgdihbj94BvjFDmOuBq4BGKWfa/rHPfaJWrgcUV108C5pfbMuDzvSpUXiAcsStJdwBftH1l07HExEg6HPi67aNGuHYFcIft68vj+4FFtjePVl8eQYuI1nnrCfv78SeqR0B+cPcz6yh6KMMGbA+M4TaHsuvk3sbyXBJmROw5tj4xyF2r51aWmXnw/z5te2GfQgKSMCOew/aipmMIM+ihyb7JJnZdDTGXXVdhPEcmfSKidQwM4cptN1gJnF7Olr8O+GXV+CWkhRkRLWTMjgmu4pJ0PbAImC1pI8XysZkAtv8JWAWcTPGQw1PAn/eqMwlznCQtBi4DZgBX2r6kqvw+2tez2L8vsUXsLtvZttX2i5u490RbkbaX9rhu4Jyx1JmEOQ7lI3SXA2+mmFlbI2ml7XtH+8ws9uc4ndivECN2i9t884bepXY/AzuY9DHMMcsY5vgcC6wvXyDxLMVbdZY0HFPElGFg0K7cmpCEOT6jrd/ahaRlktZKWruDZ/oWXMRUMNRja0K65JOoXEQ7APA8HZRHqiJqss2zLXwKMQlzfMa8fisi6iuWFbVPuuTjswaYX75xZx+Kl9SubDimiClEDPbYmpAW5jjY3ilpObCaYlnRCtvrGg4rYsowsMPNJMUqSZjjZHsVxcLXiNjNDI21IqskYUZE6xQtzPaNGCZhRkTrGDHYwimWJMyIaKWhjGFGRPRmxLNu3181TsKMiNYp1mGmSx4R0ZOdFmZERG1DWVYUEdFbsQ4zXfKIiJ6M2OH2paf2RRQRAQxmWVFERG9pYUZE1JQxzIiImozSJY+IqMMmXfKIiHqUdZgREXUUfzUyY5gRET0Vs+R5NDIiopbMkkdE1NDWFmb7UnhETHsGhrxX5daLpMWS7pe0XtJ5I1w/TNK3Jf1Q0t2STu5VZxJmRLTSRP7MrqQZwOXAScACYKmkBV3FPgrcZPsYij+V/Y+9YkqXPCJaxxY7hiaUno4F1tt+AEDSDcAS4N7O2wDPK/efDzzcq9IkzIhoneKN6xNah3ko8FDH8UbguK4yFwHflPReYH/gTb0qTZc8IlrHiB1DMyo3YLaktR3bsjHeZilwte25wMnAdZIqc2JamBHRSjWWFW21vXCUa5uAeR3Hc8tznc4CFgPY/q6kWcBsYMtoN0wLMyJax4ghV289rAHmSzpC0j4Ukzoru8r8HDgRQNLvAbOAx6oqTQszIlqnePnG+Ndh2t4paTmwGpgBrLC9TtLFwFrbK4FzgS9I+gDFsOmZtl1VbxLmOEl6ENgODAI7K7oGETEONVqRlWyvAlZ1nbugY/9e4Pix1JmEOTEn2N7adBARU01bn/RJwoyI1ime9Gnf690y6TN+pljD9YNxLGeIiEqa8KORkyEtzPF7ve1Nkl4CfEvS/9i+s7NAmUiXAcxivyZijNgjFZM+7WvPtS+iPYTtTeXPLcAtFI9idZcZsL3Q9sKZ7NvvECP2aG1sYSZhjoOk/SUdOLwPvAW4p9moIqaO3bAOc1KkSz4+c4BbJEHxHX7Z9jeaDSli6jCws4Vd8iTMcSjfgPL7TccRMZU11e2ukoQZEa1jKy3MiIi62rgOMwkzIlqnrQvXkzAjonWM2DmULnlERC0TfOP6pEjCjIjWsUkLMyKiroxhRkTUMPykT9skYUZEKw1mHWZERG92uuQRETWJwUz6RETU47QwIyJ6y5M+ERF1GQaTMCMiejPpkkdE1JR1mBERtQ0NJWFGRPRkp0seEVHbYFqYERH1tLGF2b6l9BEx7RlhV2+9SFos6X5J6yWdN0qZUyXdK2mdpC/3qjMtzIhonwk+Sy5pBnA58GZgI7BG0krb93aUmQ98BDje9jZJL+lVb1qYEdFO7rFVOxZYb/sB288CNwBLusqcDVxuexuA7S29Kk3CjIhWGhpS5dbDocBDHccby3OdjgSOlPSfkr4naXGvStMlj4jWqfmkz2xJazuOB2wPjOE2ewPzgUXAXOBOSa+2/YuqD0REtIuB3glzq+2Fo1zbBMzrOJ5bnuu0EbjL9g7gZ5J+QpFA14x2w3TJI6KVPFS99bAGmC/pCEn7AKcBK7vKfI2idYmk2RRd9AeqKk3CrCBphaQtku7pOHeQpG9J+mn584VNxhgxNU1sWZHtncByYDVwH3CT7XWSLpZ0SllsNfC4pHuBbwMfsv14Vb1JmNWuBroHgs8Dbrc9H7i9PI6I3cngIVVuPauwV9k+0vbLbX+sPHeB7ZXlvm1/0PYC26+2fUOvOpMwK9i+E3ii6/QS4Jpy/xrg7X0NKmK6mNiyokmRSZ+xm2N7c7n/CDCnyWAipq72PRqZhDkBti1p1N91kpYBywBmsV/f4oqYEnpP7PRduuRj96ikgwHKn6M+HWB7wPZC2wtnsm/fAozY4w0vK6raGpCEOXYrgTPK/TOAWxuMJWLKKt6JOfrWhCTMCpKuB74LvFLSRklnAZcAb5b0U+BN5XFE7G5Dqt4akDHMCraXjnLpxL4GEjENjT470JwkzIhoHzfXiqyShBkR7ZQWZkRETUmYERE1mHTJIyLqyqRPRERdSZgREfWkhRkRUVcL/y55EmZEtI9p5cs3kjAjopXSJY+IqCstzIiI3uS0MCMi6sukT0REPUqXPCKipnTJIyJqyBhmRMQYpEseEVFPWpgREXUlYUZE1JAxzBiP1Q//aNyffeshR+/GSCL6rIUJM39mNyJaRxTrMKu2nnVIiyXdL2m9pPMqyv2RJEta2KvOJMyIaCf32CpImgFcDpwELACWSlowQrkDgfcBd9UJKQkzItrHE25hHgust/2A7WeBG4AlI5T7W+CTwNN1wkrCjIh2mkALEzgUeKjjeGN57jckvRaYZ/tf64aUSZ+IaKUas+SzJa3tOB6wPVCrbmkv4FLgzLHElIQZEe1T743rW22PNlGzCZjXcTy3PDfsQOAo4A5JAL8LrJR0iu3OJLyLJMyIaKUJrsNcA8yXdARFojwNeNfwRdu/BGb/5l7SHcBfVSVLSMKsJGkF8DZgi+2jynMXAWcDj5XFzre9arJiyFrKmK4m8no32zslLQdWAzOAFbbXSboYWGt75XjqTcKsdjXwOeDarvOftv0P/Q8nYhqZ4ML1siGzquvcBaOUXVSnzsySV7B9J/BE03FETDu9ZsgbegooCXN8lku6W9IKSS8crZCkZZLWSlq7g2f6GV/EHk389u/6jLY1IQlz7D4PvBw4GtgMfGq0grYHbC+0vXAm+/YrvogpIQlzCrD9qO1B20PAFyieKIiI3S1d8j2fpIM7Dt8B3NNULBFT1sQfjZwUmSWvIOl6YBHFEwUbgQuBRZKOpvgd9yDwnsYCjClnvK/zm5LLz1r4erckzAq2l45w+qq+BxIxDeXP7EZE1JQ3rkdE1NHgxE6VJMyIaJ3hN663TRJmRLRTWpgRETUYNNS+jJmEGWOWpS+TJ9/Rb2XSJyKiriTMiIh6MukTEVFHgy/YqJKEGRGtk2VFERFj4fY1MZMwI6KV0iWPKSFLX2LSGTTYdBDPlYQZEe2UFmZERD3pkkdE1JFHIyMixqB9+TIJMyLaR3ZamBERdWUMMyKiriTMiJGN95VxkHWhU5JBg+3LmPm75BHRTu6x9SBpsaT7Ja2XdN4I1z8o6V5Jd0u6XdJLe9WZhBkRraQhV26Vn5VmAJcDJwELgKWSFnQV+yGw0PZrgJuBv+sVUxJmRLSSXL31cCyw3vYDtp8FbgCWdBaw/W3bT5WH3wPm9qo0CTMi2qdXd7x3wjwUeKjjeGN5bjRnAf/Wq9JM+kRE64hakz6zJa3tOB6wPTDme0nvBhYCb+xVNgkzIlpJvd+HudX2wlGubQLmdRzPLc/teg/pTcBfA2+0/UyvGyZhVpA0D7gWmEPRCRiwfZmkg4AbgcOBB4FTbW9rKs6pIEuDYhc2TOxJnzXAfElHUCTK04B3dRaQdAxwBbDY9pY6lWYMs9pO4FzbC4DXAeeUM23nAbfbng/cXh5HxG40kUkf2zuB5cBq4D7gJtvrJF0s6ZSy2N8DBwD/IulHklb2iiktzAq2NwOby/3tku6jGDheAiwqi10D3AF8uIEQI6auCf6JCturgFVd5y7o2H/TWOtMwqxJ0uHAMcBdwJwymQI8QtFlH+kzy4BlALPYb/KDjJgq8qTPnkvSAcBXgPfbfrLzmu1RFznYHrC90PbCmezbh0gjppAJPukzGZIwe5A0kyJZfsn2V8vTj0o6uLx+MFBrwDgi6pNduTUhCbOCJAFXAffZvrTj0krgjHL/DODWfscWMaUZGHT11oCMYVY7Hvgz4MeShl+ncz5wCXCTpLOADcCpvSo68jVPsXr12N/Ik+U2vY33TUf5bttLNNeKrJKEWcH2dygeOhjJif2MJWLaGRpqOoLnSMKMiPYx0L58mYQZEe2ULnlERC1OlzwiohYz4Sd9JkMSZkS0Uhuf9EnC7JOf3L1flrFMknyvU1RamBERNZiJvt5tUiRhRkQLZdInIqK+dMkjImqwYXCw6SieIwkzItopLcyIiBoy6RMRMQaZ9Iloj/G+Fm4isma0LqdLHhFRi0kLMyKitiTMiIg6nEmfiIhaDM46zIiImjLpExFRg/Ms+bS2nW1bb/PNG8rD2cDWJuMZQdtimvR4Zhw8puK7KZ71E6+i0K9/Xy/twz1GlC75NGb7xcP7ktbaXthkPN3aFlPiqda2eHa/dq7D3KvpACIinsMUL9+o2nqQtFjS/ZLWSzpvhOv7SrqxvH6XpMN71ZmEGRGtY8BDrtyqSJoBXA6cBCwAlkpa0FXsLGCb7VcAnwY+2SuuJMxmDDQdwAjaFlPiqda2eHYvGzxUvVU7Flhv+wHbzwI3AEu6yiwBrin3bwZOlKSqSpMwG2C7df+xty2mxFOtbfFMBg8OVm49HAo81HG8sTw3YhnbO4FfAi+qqjSTPhHROtvZtvo23zy7R7FZktZ2HA9M9i+SJMw+k7QYuAyYAVxp+5KG43kQ2A4MAjubmHmVtAJ4G7DF9lHluYOAG4HDgQeBU21vazCei4CzgcfKYufbXtWneOYB1wJzKIb3Bmxf1uR3NNlsL55gFZuAeR3Hc8tzI5XZKGlv4PnA41WVpkveRzUHoptwgu2jG1ymcjXQ/T/IecDttucDt5fHTcYD8Onyezq6X8mytBM41/YC4HXAOeV/N01+R223Bpgv6QhJ+wCnASu7yqwEzij33wn8u129likJs7/qDERPO7bvBJ7oOt05IH8N8PaG42mM7c22/7vc3w7cRzH+1th31HblmORyYDXF93WT7XWSLpZ0SlnsKuBFktYDH6TGL5x0yftrpIHo4xqKZZiBb0oycEWLJhPm2N5c7j9C0R1t2nJJpwNrKVp8fe/+lmsFjwHuop3fUWuUvYBVXecu6Nh/GvjjsdSZFma83vZrKYYJzpH0hqYD6lZ2k5p+7OPzwMuBo4HNwKf6HYCkA4CvAO+3/WTntZZ8R1NeEmZ/1RmI7ivbm8qfW4BbKIYN2uBRSQcDlD+3NBmM7UdtD9oeAr5An78nSTMpkuWXbH+1PN2q72g6SMLsrzoD0X0jaX9JBw7vA28B7mkqni6dA/JnALc2GMtwQhr2Dvr4PZWLqa8C7rN9acelVn1H04F6TArFbibpZOAzFMuKVtj+WIOxvIyiVQnFePaXm4hH0vXAIoo38DwKXAh8DbgJOAzYQLFkpi8TMaPEs4iiO26KJTzv6Rg/nOx4Xg/8B/BjYPgRl/MpxjEb+Y6mqyTMiIia0iWPiKgpCTMioqYkzIiImpIwIyJqSsKMiKgpCTMioqYkzIiImpIwIyJq+n8jPeV21mqw2wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x230.4 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndQru9Cv1XIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_matrix=[]\n",
        "all_labels=[]\n",
        "all_updown_labels=[]\n",
        "for songs in bar_label_list:\n",
        "  for label in songs:\n",
        "    label=np.array(label)\n",
        "    all_labels.append(label)\n",
        "bar_label_list=[]#램 터짐\n",
        "for songs in bar_matrix_list3:\n",
        "  for matrix in songs:\n",
        "    matrix=matrix.reshape(24,24,1)\n",
        "    all_matrix.append(matrix)\n",
        "for songs in bar_updown_list:\n",
        "  for label in songs:\n",
        "    all_updown_labels.append(label)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLD6jvcH2thx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24563f89-4b67-4be3-9d5a-a5b929f90c13"
      },
      "source": [
        "print(len(all_matrix),len(all_labels),len(all_updown_labels))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175857 175857 175857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxnqzorC35O4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0900a849-ee4d-4227-ffd6-60d8aa93eef4"
      },
      "source": [
        "import keras.backend.tensorflow_backend as tfback\n",
        "from tensorflow.python.client import device_lib\n",
        "def _get_available_gpus():\n",
        "  if tfback._LOCAL_DEVICES is None:\n",
        "    devices = device_lib.list_local_devices()\n",
        "    tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "  return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "tfback._get_available_gpus = _get_available_gpus\n",
        "tfback._get_available_gpus()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mt2exWUggwA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "train_matrix=np.array(all_matrix[:150000])\n",
        "train_label=np.array(all_labels[:150000])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc4SuOnd9wC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_labels():\n",
        "  labels=[]\n",
        "  label_tuple=[]\n",
        "  skills_pitch=['repeating','up_steping','down_steping','up_leaping','down_leaping','steping_twisting','leaping_twisting','dummy']\n",
        "  skills_timing=['resting','fast_rhythm','dummy']\n",
        "  skills_triplet=['triplet','dummy']\n",
        "  skills_one_rhythm=['One_rhythm','dummy']\n",
        "  skills_staccato=['staccato','continuing_rhythm','dummy']\n",
        "  for pitch in skills_pitch:\n",
        "    for timing in skills_timing:\n",
        "      for triplet in skills_triplet:\n",
        "        for one_rhythm in skills_one_rhythm:\n",
        "          for staccato in skills_staccato:\n",
        "            label_tuple=[]\n",
        "            if pitch is not 'dummy':\n",
        "              label_tuple.append(pitch)\n",
        "            if timing is not 'dummy':\n",
        "              label_tuple.append(timing)\n",
        "            if triplet is not 'dummy':\n",
        "              label_tuple.append(triplet)\n",
        "            if one_rhythm is not 'dummy':\n",
        "              label_tuple.append(one_rhythm)\n",
        "            if staccato is not 'dummy':\n",
        "              label_tuple.append(staccato)\n",
        "            label_tuple=tuple(label_tuple)\n",
        "            labels.append(label_tuple)\n",
        "  return labels"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYOhSlmHA1ka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "145fab13-6578-4a83-f16a-3a3c2aa6189c"
      },
      "source": [
        "label=set_labels()\n",
        "print(label)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('repeating', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('repeating', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('repeating', 'resting', 'triplet', 'One_rhythm'), ('repeating', 'resting', 'triplet', 'staccato'), ('repeating', 'resting', 'triplet', 'continuing_rhythm'), ('repeating', 'resting', 'triplet'), ('repeating', 'resting', 'One_rhythm', 'staccato'), ('repeating', 'resting', 'One_rhythm', 'continuing_rhythm'), ('repeating', 'resting', 'One_rhythm'), ('repeating', 'resting', 'staccato'), ('repeating', 'resting', 'continuing_rhythm'), ('repeating', 'resting'), ('repeating', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('repeating', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('repeating', 'fast_rhythm', 'triplet', 'One_rhythm'), ('repeating', 'fast_rhythm', 'triplet', 'staccato'), ('repeating', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('repeating', 'fast_rhythm', 'triplet'), ('repeating', 'fast_rhythm', 'One_rhythm', 'staccato'), ('repeating', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('repeating', 'fast_rhythm', 'One_rhythm'), ('repeating', 'fast_rhythm', 'staccato'), ('repeating', 'fast_rhythm', 'continuing_rhythm'), ('repeating', 'fast_rhythm'), ('repeating', 'triplet', 'One_rhythm', 'staccato'), ('repeating', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('repeating', 'triplet', 'One_rhythm'), ('repeating', 'triplet', 'staccato'), ('repeating', 'triplet', 'continuing_rhythm'), ('repeating', 'triplet'), ('repeating', 'One_rhythm', 'staccato'), ('repeating', 'One_rhythm', 'continuing_rhythm'), ('repeating', 'One_rhythm'), ('repeating', 'staccato'), ('repeating', 'continuing_rhythm'), ('repeating',), ('up_steping', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('up_steping', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('up_steping', 'resting', 'triplet', 'One_rhythm'), ('up_steping', 'resting', 'triplet', 'staccato'), ('up_steping', 'resting', 'triplet', 'continuing_rhythm'), ('up_steping', 'resting', 'triplet'), ('up_steping', 'resting', 'One_rhythm', 'staccato'), ('up_steping', 'resting', 'One_rhythm', 'continuing_rhythm'), ('up_steping', 'resting', 'One_rhythm'), ('up_steping', 'resting', 'staccato'), ('up_steping', 'resting', 'continuing_rhythm'), ('up_steping', 'resting'), ('up_steping', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('up_steping', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('up_steping', 'fast_rhythm', 'triplet', 'One_rhythm'), ('up_steping', 'fast_rhythm', 'triplet', 'staccato'), ('up_steping', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('up_steping', 'fast_rhythm', 'triplet'), ('up_steping', 'fast_rhythm', 'One_rhythm', 'staccato'), ('up_steping', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('up_steping', 'fast_rhythm', 'One_rhythm'), ('up_steping', 'fast_rhythm', 'staccato'), ('up_steping', 'fast_rhythm', 'continuing_rhythm'), ('up_steping', 'fast_rhythm'), ('up_steping', 'triplet', 'One_rhythm', 'staccato'), ('up_steping', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('up_steping', 'triplet', 'One_rhythm'), ('up_steping', 'triplet', 'staccato'), ('up_steping', 'triplet', 'continuing_rhythm'), ('up_steping', 'triplet'), ('up_steping', 'One_rhythm', 'staccato'), ('up_steping', 'One_rhythm', 'continuing_rhythm'), ('up_steping', 'One_rhythm'), ('up_steping', 'staccato'), ('up_steping', 'continuing_rhythm'), ('up_steping',), ('down_steping', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('down_steping', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('down_steping', 'resting', 'triplet', 'One_rhythm'), ('down_steping', 'resting', 'triplet', 'staccato'), ('down_steping', 'resting', 'triplet', 'continuing_rhythm'), ('down_steping', 'resting', 'triplet'), ('down_steping', 'resting', 'One_rhythm', 'staccato'), ('down_steping', 'resting', 'One_rhythm', 'continuing_rhythm'), ('down_steping', 'resting', 'One_rhythm'), ('down_steping', 'resting', 'staccato'), ('down_steping', 'resting', 'continuing_rhythm'), ('down_steping', 'resting'), ('down_steping', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('down_steping', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('down_steping', 'fast_rhythm', 'triplet', 'One_rhythm'), ('down_steping', 'fast_rhythm', 'triplet', 'staccato'), ('down_steping', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('down_steping', 'fast_rhythm', 'triplet'), ('down_steping', 'fast_rhythm', 'One_rhythm', 'staccato'), ('down_steping', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('down_steping', 'fast_rhythm', 'One_rhythm'), ('down_steping', 'fast_rhythm', 'staccato'), ('down_steping', 'fast_rhythm', 'continuing_rhythm'), ('down_steping', 'fast_rhythm'), ('down_steping', 'triplet', 'One_rhythm', 'staccato'), ('down_steping', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('down_steping', 'triplet', 'One_rhythm'), ('down_steping', 'triplet', 'staccato'), ('down_steping', 'triplet', 'continuing_rhythm'), ('down_steping', 'triplet'), ('down_steping', 'One_rhythm', 'staccato'), ('down_steping', 'One_rhythm', 'continuing_rhythm'), ('down_steping', 'One_rhythm'), ('down_steping', 'staccato'), ('down_steping', 'continuing_rhythm'), ('down_steping',), ('up_leaping', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('up_leaping', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('up_leaping', 'resting', 'triplet', 'One_rhythm'), ('up_leaping', 'resting', 'triplet', 'staccato'), ('up_leaping', 'resting', 'triplet', 'continuing_rhythm'), ('up_leaping', 'resting', 'triplet'), ('up_leaping', 'resting', 'One_rhythm', 'staccato'), ('up_leaping', 'resting', 'One_rhythm', 'continuing_rhythm'), ('up_leaping', 'resting', 'One_rhythm'), ('up_leaping', 'resting', 'staccato'), ('up_leaping', 'resting', 'continuing_rhythm'), ('up_leaping', 'resting'), ('up_leaping', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('up_leaping', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('up_leaping', 'fast_rhythm', 'triplet', 'One_rhythm'), ('up_leaping', 'fast_rhythm', 'triplet', 'staccato'), ('up_leaping', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('up_leaping', 'fast_rhythm', 'triplet'), ('up_leaping', 'fast_rhythm', 'One_rhythm', 'staccato'), ('up_leaping', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('up_leaping', 'fast_rhythm', 'One_rhythm'), ('up_leaping', 'fast_rhythm', 'staccato'), ('up_leaping', 'fast_rhythm', 'continuing_rhythm'), ('up_leaping', 'fast_rhythm'), ('up_leaping', 'triplet', 'One_rhythm', 'staccato'), ('up_leaping', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('up_leaping', 'triplet', 'One_rhythm'), ('up_leaping', 'triplet', 'staccato'), ('up_leaping', 'triplet', 'continuing_rhythm'), ('up_leaping', 'triplet'), ('up_leaping', 'One_rhythm', 'staccato'), ('up_leaping', 'One_rhythm', 'continuing_rhythm'), ('up_leaping', 'One_rhythm'), ('up_leaping', 'staccato'), ('up_leaping', 'continuing_rhythm'), ('up_leaping',), ('down_leaping', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('down_leaping', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('down_leaping', 'resting', 'triplet', 'One_rhythm'), ('down_leaping', 'resting', 'triplet', 'staccato'), ('down_leaping', 'resting', 'triplet', 'continuing_rhythm'), ('down_leaping', 'resting', 'triplet'), ('down_leaping', 'resting', 'One_rhythm', 'staccato'), ('down_leaping', 'resting', 'One_rhythm', 'continuing_rhythm'), ('down_leaping', 'resting', 'One_rhythm'), ('down_leaping', 'resting', 'staccato'), ('down_leaping', 'resting', 'continuing_rhythm'), ('down_leaping', 'resting'), ('down_leaping', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('down_leaping', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('down_leaping', 'fast_rhythm', 'triplet', 'One_rhythm'), ('down_leaping', 'fast_rhythm', 'triplet', 'staccato'), ('down_leaping', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('down_leaping', 'fast_rhythm', 'triplet'), ('down_leaping', 'fast_rhythm', 'One_rhythm', 'staccato'), ('down_leaping', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('down_leaping', 'fast_rhythm', 'One_rhythm'), ('down_leaping', 'fast_rhythm', 'staccato'), ('down_leaping', 'fast_rhythm', 'continuing_rhythm'), ('down_leaping', 'fast_rhythm'), ('down_leaping', 'triplet', 'One_rhythm', 'staccato'), ('down_leaping', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('down_leaping', 'triplet', 'One_rhythm'), ('down_leaping', 'triplet', 'staccato'), ('down_leaping', 'triplet', 'continuing_rhythm'), ('down_leaping', 'triplet'), ('down_leaping', 'One_rhythm', 'staccato'), ('down_leaping', 'One_rhythm', 'continuing_rhythm'), ('down_leaping', 'One_rhythm'), ('down_leaping', 'staccato'), ('down_leaping', 'continuing_rhythm'), ('down_leaping',), ('steping_twisting', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('steping_twisting', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('steping_twisting', 'resting', 'triplet', 'One_rhythm'), ('steping_twisting', 'resting', 'triplet', 'staccato'), ('steping_twisting', 'resting', 'triplet', 'continuing_rhythm'), ('steping_twisting', 'resting', 'triplet'), ('steping_twisting', 'resting', 'One_rhythm', 'staccato'), ('steping_twisting', 'resting', 'One_rhythm', 'continuing_rhythm'), ('steping_twisting', 'resting', 'One_rhythm'), ('steping_twisting', 'resting', 'staccato'), ('steping_twisting', 'resting', 'continuing_rhythm'), ('steping_twisting', 'resting'), ('steping_twisting', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('steping_twisting', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('steping_twisting', 'fast_rhythm', 'triplet', 'One_rhythm'), ('steping_twisting', 'fast_rhythm', 'triplet', 'staccato'), ('steping_twisting', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('steping_twisting', 'fast_rhythm', 'triplet'), ('steping_twisting', 'fast_rhythm', 'One_rhythm', 'staccato'), ('steping_twisting', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('steping_twisting', 'fast_rhythm', 'One_rhythm'), ('steping_twisting', 'fast_rhythm', 'staccato'), ('steping_twisting', 'fast_rhythm', 'continuing_rhythm'), ('steping_twisting', 'fast_rhythm'), ('steping_twisting', 'triplet', 'One_rhythm', 'staccato'), ('steping_twisting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('steping_twisting', 'triplet', 'One_rhythm'), ('steping_twisting', 'triplet', 'staccato'), ('steping_twisting', 'triplet', 'continuing_rhythm'), ('steping_twisting', 'triplet'), ('steping_twisting', 'One_rhythm', 'staccato'), ('steping_twisting', 'One_rhythm', 'continuing_rhythm'), ('steping_twisting', 'One_rhythm'), ('steping_twisting', 'staccato'), ('steping_twisting', 'continuing_rhythm'), ('steping_twisting',), ('leaping_twisting', 'resting', 'triplet', 'One_rhythm', 'staccato'), ('leaping_twisting', 'resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'resting', 'triplet', 'One_rhythm'), ('leaping_twisting', 'resting', 'triplet', 'staccato'), ('leaping_twisting', 'resting', 'triplet', 'continuing_rhythm'), ('leaping_twisting', 'resting', 'triplet'), ('leaping_twisting', 'resting', 'One_rhythm', 'staccato'), ('leaping_twisting', 'resting', 'One_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'resting', 'One_rhythm'), ('leaping_twisting', 'resting', 'staccato'), ('leaping_twisting', 'resting', 'continuing_rhythm'), ('leaping_twisting', 'resting'), ('leaping_twisting', 'fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('leaping_twisting', 'fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'fast_rhythm', 'triplet', 'One_rhythm'), ('leaping_twisting', 'fast_rhythm', 'triplet', 'staccato'), ('leaping_twisting', 'fast_rhythm', 'triplet', 'continuing_rhythm'), ('leaping_twisting', 'fast_rhythm', 'triplet'), ('leaping_twisting', 'fast_rhythm', 'One_rhythm', 'staccato'), ('leaping_twisting', 'fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'fast_rhythm', 'One_rhythm'), ('leaping_twisting', 'fast_rhythm', 'staccato'), ('leaping_twisting', 'fast_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'fast_rhythm'), ('leaping_twisting', 'triplet', 'One_rhythm', 'staccato'), ('leaping_twisting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'triplet', 'One_rhythm'), ('leaping_twisting', 'triplet', 'staccato'), ('leaping_twisting', 'triplet', 'continuing_rhythm'), ('leaping_twisting', 'triplet'), ('leaping_twisting', 'One_rhythm', 'staccato'), ('leaping_twisting', 'One_rhythm', 'continuing_rhythm'), ('leaping_twisting', 'One_rhythm'), ('leaping_twisting', 'staccato'), ('leaping_twisting', 'continuing_rhythm'), ('leaping_twisting',), ('resting', 'triplet', 'One_rhythm', 'staccato'), ('resting', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('resting', 'triplet', 'One_rhythm'), ('resting', 'triplet', 'staccato'), ('resting', 'triplet', 'continuing_rhythm'), ('resting', 'triplet'), ('resting', 'One_rhythm', 'staccato'), ('resting', 'One_rhythm', 'continuing_rhythm'), ('resting', 'One_rhythm'), ('resting', 'staccato'), ('resting', 'continuing_rhythm'), ('resting',), ('fast_rhythm', 'triplet', 'One_rhythm', 'staccato'), ('fast_rhythm', 'triplet', 'One_rhythm', 'continuing_rhythm'), ('fast_rhythm', 'triplet', 'One_rhythm'), ('fast_rhythm', 'triplet', 'staccato'), ('fast_rhythm', 'triplet', 'continuing_rhythm'), ('fast_rhythm', 'triplet'), ('fast_rhythm', 'One_rhythm', 'staccato'), ('fast_rhythm', 'One_rhythm', 'continuing_rhythm'), ('fast_rhythm', 'One_rhythm'), ('fast_rhythm', 'staccato'), ('fast_rhythm', 'continuing_rhythm'), ('fast_rhythm',), ('triplet', 'One_rhythm', 'staccato'), ('triplet', 'One_rhythm', 'continuing_rhythm'), ('triplet', 'One_rhythm'), ('triplet', 'staccato'), ('triplet', 'continuing_rhythm'), ('triplet',), ('One_rhythm', 'staccato'), ('One_rhythm', 'continuing_rhythm'), ('One_rhythm',), ('staccato',), ('continuing_rhythm',), ()]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93yFDiw86QyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_matrix=np.array(all_matrix[150000:170000])\n",
        "valid_label=np.array(all_labels[150000:170000])\n",
        "test_matrix=np.array(all_matrix[170000:])\n",
        "test_label=np.array(all_labels[170000:])#어쩌면 쓸수도?\n",
        "mlb=MultiLabelBinarizer()\n",
        "labels=set_labels()\n",
        "mlb.fit(labels)\n",
        "train_label2=mlb.transform(train_label)\n",
        "valid_label2=mlb.transform(valid_label)\n",
        "test_label2=mlb.transform(test_label)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPUsl9deYgNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d30df9c8-d384-46b8-f4f2-b23d7006c4ed"
      },
      "source": [
        "print(train_label2.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MoUdnPf62cX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "updownle=LabelBinarizer()\n",
        "updownle.fit(['up','down','final','meanless'])\n",
        "updown_label=updownle.transform(np.array(all_updown_labels))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfUeYxwX8eVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_updown_label=updown_label[:150000]\n",
        "valid_updown_label=updown_label[150000:170000]\n",
        "test_updown_label=updown_label[170000:]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flwJh4SmmzuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_matrix=[]\n",
        "all_labels=[]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb3xLrR99Rk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "b81b85a5-7fed-43fe-f797-428183ed2d85"
      },
      "source": [
        "print(train_matrix.shape)\n",
        "print(train_label2)\n",
        "print(valid_matrix.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 24, 24, 1)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "(20000, 24, 24, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkGYxpDB8ky9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.applications\n",
        "from keras import regularizers\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import resnet50\n",
        "from keras import layers\n",
        "from tensorflow import keras\n",
        "def residual_block(filter, input, add=True):\n",
        "  with tf.device('/gpu:0'):\n",
        "    layer_1 = keras.layers.Conv2D(filters=filter//4, kernel_size=(1, 1), data_format=\"channels_first\")(input)\n",
        "    layer_2 = keras.layers.Conv2D(filters=filter//4, kernel_size=(3, 3), padding='same', data_format=\"channels_first\", kernel_regularizer=keras.regularizers.l2(0.001))(layer_1)\n",
        "    layer_2 = keras.layers.BatchNormalization()(layer_2)\n",
        "    layer_2 = keras.layers.ReLU()(layer_2)\n",
        "    layer_3 = keras.layers.Conv2D(filters=filter, kernel_size=(1, 1), data_format=\"channels_first\")(layer_2)\n",
        "    layer_3 = keras.layers.BatchNormalization()(layer_3)\n",
        "    if add:\n",
        "        layer_3 = keras.layers.add([input, layer_3])\n",
        "    layer_3 = keras.layers.ReLU()(layer_3)\n",
        "    return layer_3\n",
        "def make_model():\n",
        "  with tf.device('/gpu:0'):\n",
        "    input_layer = keras.Input(shape=(24, 24, 1))\n",
        "    layer_1 = keras.layers.Conv2D(filters=64, kernel_size=(7, 7), padding='same', data_format=\"channels_first\")(input_layer)\n",
        "    block_1 = residual_block(64, layer_1)\n",
        "    #block_2 = residual_block(64, block_1)\n",
        "    #block_3 = residual_block(64, block_2)\n",
        "    pooling_layer = keras.layers.MaxPool2D((2, 2),padding='same', data_format=\"channels_first\")(block_1)\n",
        "    block_4 = residual_block(128, pooling_layer, add=False)\n",
        "    block_5 = residual_block(128, block_4)\n",
        "    #block_6 = residual_block(128, block_5)\n",
        "    pooling_layer2 = keras.layers.MaxPool2D(padding='same',pool_size=(2, 2), data_format=\"channels_first\")(block_4)\n",
        "    block_7 = residual_block(256, pooling_layer2, add=False)\n",
        "    block_8 = residual_block(256, block_7)\n",
        "    block_9 = residual_block(256, block_8)\n",
        "    #pooling_layer4 = keras.layers.MaxPool2D(pool_size=(2, 2), data_format=\"channels_first\")(block_7)\n",
        "    #block_10 = residual_block(256, pooling_layer4)\n",
        "    #block_11 = residual_block(512, block_10)\n",
        "    pooling_layer3 = keras.layers.AvgPool2D(padding='same',pool_size=(8, 8), data_format=\"channels_first\")(block_7)\n",
        "    last_layer = keras.layers.Flatten()(pooling_layer3)\n",
        "    last_layer = keras.layers.Dropout(0.4)(last_layer)\n",
        "    last_layer = keras.layers.Dense(13, activation=\"sigmoid\")(last_layer)\n",
        "    return keras.models.Model(inputs=input_layer, outputs=last_layer)\n",
        "def make_classifier():\n",
        "  with tf.device('/gpu:0'):\n",
        "    classifier = keras.Sequential()\n",
        "    classifier.add(keras.layers.Conv2D(128, kernel_size=(5, 5), strides=(1, 1), padding='same',\n",
        "                  activation='relu',\n",
        "                  input_shape=(24,24,1)))\n",
        "    classifier.add(keras.layers.BatchNormalization())\n",
        "    classifier.add(keras.layers.LeakyReLU(alpha=0.01))\n",
        "    classifier.add(keras.layers.Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
        "    classifier.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    classifier.add(keras.layers.Conv2D(256, (2, 2), padding='same'))\n",
        "    classifier.add(keras.layers.LeakyReLU(alpha=0.01))\n",
        "    classifier.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    classifier.add(keras.layers.Flatten())\n",
        "    classifier.add(keras.layers.Dropout(0.25))\n",
        "    classifier.add(keras.layers.Dense(4, activation='sigmoid'))\n",
        "  return classifier"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn-X5lReh2ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "model_path = '/content/drive/My Drive/models/' + 'deeperppddbest.h5'\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_acc',\n",
        "                                verbose=1, save_best_only=True)\n",
        "callbacks = [cb_checkpoint]\n",
        "\n",
        "model_path = '/content/drive/My Drive/models/' + 'updown.h5'\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_acc',\n",
        "                                verbose=1, save_best_only=True)\n",
        "updown_callbacks=[cb_checkpoint]\n",
        "#tf.keras의 경우(make_model) monitor='val_acc'로, keras의 경우(make_classifier) monitor='val_accuracy'로 해야한다."
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf1jJnIxemG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "def recall(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
        "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
        "\n",
        "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return recall\n",
        "\n",
        "\n",
        "def precision(y_target, y_pred):\n",
        "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
        "    # round : 반올림한다\n",
        "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "    y_target_yn = K.round(K.clip(y_target, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
        "\n",
        "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
        "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
        "\n",
        "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
        "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
        "\n",
        "    # Precision = (True Positive) / (True Positive + False Positive)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
        "\n",
        "    # return a single tensor value\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1score(y_target, y_pred):\n",
        "    _recall = recall(y_target, y_pred)\n",
        "    _precision = precision(y_target, y_pred)\n",
        "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
        "    _f1score = ( 2 * _recall * _precision) / (_recall + _precision+ K.epsilon())\n",
        "    \n",
        "    # return a single tensor value\n",
        "    return _f1score\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2Nx8Ygs-I6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c7d95b24-7bf6-4be0-bca5-f6e5334cb4b8"
      },
      "source": [
        "from tensorflow import keras\n",
        "classifier=make_model()\n",
        "classifier.compile(loss=keras.losses.BinaryCrossentropy(\n",
        "      from_logits=False, label_smoothing=0.1, \n",
        "      name='binary_crossentropy'\n",
        "  ), optimizer='adam', metrics=['accuracy',recall,precision,f1score])\n",
        "\"\"\"\n",
        "hist=classifier.fit(\n",
        "      train_matrix,train_label2,batch_size=256,\n",
        "      epochs=150,\n",
        "      validation_data=(valid_matrix,valid_label2),\n",
        "      callbacks=callbacks,\n",
        "  )\n",
        "\"\"\"\n",
        "\n",
        "#실제 학습\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhist=classifier.fit(\\n      train_matrix,train_label2,batch_size=256,\\n      epochs=150,\\n      validation_data=(valid_matrix,valid_label2),\\n      callbacks=callbacks,\\n  )\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ8oiBIhX7kq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c87057f5-e1ef-48a4-b9ce-0d2c90b0a365"
      },
      "source": [
        "#음의 흐름에 관한 분류기\n",
        "updown_classifier=make_classifier()\n",
        "updown_classifier.compile(loss=keras.losses.BinaryCrossentropy(\n",
        "      from_logits=False,\n",
        "      name='binary_crossentorpy'\n",
        "  ), optimizer='adam', metrics=['accuracy'])\n",
        "updown_hist=updown_classifier.fit(\n",
        "      train_matrix,train_updown_label,batch_size=256,\n",
        "      epochs=150,\n",
        "      validation_data=(valid_matrix,valid_updown_label),\n",
        "      callbacks=updown_callbacks,\n",
        "  )\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 150000 samples, validate on 20000 samples\n",
            "Epoch 1/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.3370 - acc: 0.8364\n",
            "Epoch 00001: val_acc did not improve from 0.84052\n",
            "150000/150000 [==============================] - 20s 131us/sample - loss: 0.3370 - acc: 0.8364 - val_loss: 0.3756 - val_acc: 0.8274\n",
            "Epoch 2/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.8463\n",
            "Epoch 00002: val_acc did not improve from 0.84052\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.3234 - acc: 0.8464 - val_loss: 0.3391 - val_acc: 0.8352\n",
            "Epoch 3/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.8506\n",
            "Epoch 00003: val_acc did not improve from 0.84052\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.3175 - acc: 0.8506 - val_loss: 0.3406 - val_acc: 0.8369\n",
            "Epoch 4/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.3129 - acc: 0.8538\n",
            "Epoch 00004: val_acc did not improve from 0.84052\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.3129 - acc: 0.8538 - val_loss: 0.3380 - val_acc: 0.8402\n",
            "Epoch 5/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.3080 - acc: 0.8569\n",
            "Epoch 00005: val_acc did not improve from 0.84052\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.3080 - acc: 0.8569 - val_loss: 0.3377 - val_acc: 0.8389\n",
            "Epoch 6/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.8601\n",
            "Epoch 00006: val_acc improved from 0.84052 to 0.84059, saving model to /content/drive/My Drive/models/updown.h5\n",
            "150000/150000 [==============================] - 23s 150us/sample - loss: 0.3033 - acc: 0.8601 - val_loss: 0.3346 - val_acc: 0.8406\n",
            "Epoch 7/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.8629\n",
            "Epoch 00007: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.2984 - acc: 0.8628 - val_loss: 0.3348 - val_acc: 0.8399\n",
            "Epoch 8/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2938 - acc: 0.8661\n",
            "Epoch 00008: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2938 - acc: 0.8661 - val_loss: 0.3467 - val_acc: 0.8356\n",
            "Epoch 9/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.8689\n",
            "Epoch 00009: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2885 - acc: 0.8689 - val_loss: 0.3511 - val_acc: 0.8348\n",
            "Epoch 10/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2833 - acc: 0.8720\n",
            "Epoch 00010: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2834 - acc: 0.8720 - val_loss: 0.3481 - val_acc: 0.8356\n",
            "Epoch 11/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.8745\n",
            "Epoch 00011: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2786 - acc: 0.8745 - val_loss: 0.3625 - val_acc: 0.8333\n",
            "Epoch 12/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.8774\n",
            "Epoch 00012: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2740 - acc: 0.8773 - val_loss: 0.3599 - val_acc: 0.8353\n",
            "Epoch 13/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2692 - acc: 0.8794\n",
            "Epoch 00013: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2692 - acc: 0.8794 - val_loss: 0.3632 - val_acc: 0.8363\n",
            "Epoch 14/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.8817\n",
            "Epoch 00014: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2651 - acc: 0.8817 - val_loss: 0.3713 - val_acc: 0.8338\n",
            "Epoch 15/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2610 - acc: 0.8840\n",
            "Epoch 00015: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2610 - acc: 0.8840 - val_loss: 0.3715 - val_acc: 0.8322\n",
            "Epoch 16/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.8860\n",
            "Epoch 00016: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2573 - acc: 0.8860 - val_loss: 0.3710 - val_acc: 0.8342\n",
            "Epoch 17/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.8879\n",
            "Epoch 00017: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2532 - acc: 0.8879 - val_loss: 0.3788 - val_acc: 0.8307\n",
            "Epoch 18/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.8894\n",
            "Epoch 00018: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2503 - acc: 0.8894 - val_loss: 0.3791 - val_acc: 0.8342\n",
            "Epoch 19/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2476 - acc: 0.8904\n",
            "Epoch 00019: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2476 - acc: 0.8904 - val_loss: 0.3836 - val_acc: 0.8339\n",
            "Epoch 20/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.8928\n",
            "Epoch 00020: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2447 - acc: 0.8928 - val_loss: 0.3865 - val_acc: 0.8297\n",
            "Epoch 21/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.8936\n",
            "Epoch 00021: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2419 - acc: 0.8937 - val_loss: 0.3882 - val_acc: 0.8302\n",
            "Epoch 22/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.8957\n",
            "Epoch 00022: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2386 - acc: 0.8957 - val_loss: 0.3949 - val_acc: 0.8305\n",
            "Epoch 23/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.8963\n",
            "Epoch 00023: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2368 - acc: 0.8963 - val_loss: 0.4033 - val_acc: 0.8309\n",
            "Epoch 24/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.8969\n",
            "Epoch 00024: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2355 - acc: 0.8969 - val_loss: 0.4021 - val_acc: 0.8290\n",
            "Epoch 25/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.8983\n",
            "Epoch 00025: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2331 - acc: 0.8983 - val_loss: 0.4073 - val_acc: 0.8308\n",
            "Epoch 26/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2307 - acc: 0.8992\n",
            "Epoch 00026: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2307 - acc: 0.8992 - val_loss: 0.4116 - val_acc: 0.8312\n",
            "Epoch 27/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9002\n",
            "Epoch 00027: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2294 - acc: 0.9002 - val_loss: 0.4127 - val_acc: 0.8296\n",
            "Epoch 28/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9009\n",
            "Epoch 00028: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2271 - acc: 0.9009 - val_loss: 0.4199 - val_acc: 0.8316\n",
            "Epoch 29/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9021\n",
            "Epoch 00029: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2253 - acc: 0.9021 - val_loss: 0.4230 - val_acc: 0.8293\n",
            "Epoch 30/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9028\n",
            "Epoch 00030: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2241 - acc: 0.9028 - val_loss: 0.4182 - val_acc: 0.8298\n",
            "Epoch 31/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2225 - acc: 0.9033\n",
            "Epoch 00031: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2225 - acc: 0.9033 - val_loss: 0.4293 - val_acc: 0.8307\n",
            "Epoch 32/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9046\n",
            "Epoch 00032: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2208 - acc: 0.9046 - val_loss: 0.4265 - val_acc: 0.8298\n",
            "Epoch 33/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9051\n",
            "Epoch 00033: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2197 - acc: 0.9051 - val_loss: 0.4282 - val_acc: 0.8279\n",
            "Epoch 34/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9050\n",
            "Epoch 00034: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2182 - acc: 0.9050 - val_loss: 0.4309 - val_acc: 0.8291\n",
            "Epoch 35/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9057\n",
            "Epoch 00035: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2169 - acc: 0.9057 - val_loss: 0.4368 - val_acc: 0.8261\n",
            "Epoch 36/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9070\n",
            "Epoch 00036: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2156 - acc: 0.9070 - val_loss: 0.4355 - val_acc: 0.8272\n",
            "Epoch 37/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9078\n",
            "Epoch 00037: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2147 - acc: 0.9078 - val_loss: 0.4394 - val_acc: 0.8270\n",
            "Epoch 38/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9081\n",
            "Epoch 00038: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2126 - acc: 0.9081 - val_loss: 0.4442 - val_acc: 0.8272\n",
            "Epoch 39/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9081\n",
            "Epoch 00039: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2123 - acc: 0.9081 - val_loss: 0.4449 - val_acc: 0.8310\n",
            "Epoch 40/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9092\n",
            "Epoch 00040: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2113 - acc: 0.9092 - val_loss: 0.4455 - val_acc: 0.8277\n",
            "Epoch 41/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9092\n",
            "Epoch 00041: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2106 - acc: 0.9092 - val_loss: 0.4522 - val_acc: 0.8267\n",
            "Epoch 42/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9099\n",
            "Epoch 00042: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2093 - acc: 0.9099 - val_loss: 0.4520 - val_acc: 0.8272\n",
            "Epoch 43/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9108\n",
            "Epoch 00043: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2080 - acc: 0.9107 - val_loss: 0.4556 - val_acc: 0.8283\n",
            "Epoch 44/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9107\n",
            "Epoch 00044: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2071 - acc: 0.9107 - val_loss: 0.4519 - val_acc: 0.8262\n",
            "Epoch 45/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9111\n",
            "Epoch 00045: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2060 - acc: 0.9111 - val_loss: 0.4550 - val_acc: 0.8280\n",
            "Epoch 46/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9115\n",
            "Epoch 00046: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2056 - acc: 0.9115 - val_loss: 0.4561 - val_acc: 0.8289\n",
            "Epoch 47/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2049 - acc: 0.9117\n",
            "Epoch 00047: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2050 - acc: 0.9117 - val_loss: 0.4568 - val_acc: 0.8271\n",
            "Epoch 48/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2047 - acc: 0.9114\n",
            "Epoch 00048: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2047 - acc: 0.9114 - val_loss: 0.4583 - val_acc: 0.8286\n",
            "Epoch 49/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9129\n",
            "Epoch 00049: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2025 - acc: 0.9129 - val_loss: 0.4691 - val_acc: 0.8272\n",
            "Epoch 50/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9134\n",
            "Epoch 00050: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2027 - acc: 0.9133 - val_loss: 0.4687 - val_acc: 0.8255\n",
            "Epoch 51/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9137\n",
            "Epoch 00051: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.2014 - acc: 0.9137 - val_loss: 0.4692 - val_acc: 0.8265\n",
            "Epoch 52/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9136\n",
            "Epoch 00052: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.2007 - acc: 0.9136 - val_loss: 0.4643 - val_acc: 0.8286\n",
            "Epoch 53/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9142\n",
            "Epoch 00053: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1997 - acc: 0.9142 - val_loss: 0.4629 - val_acc: 0.8273\n",
            "Epoch 54/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9143\n",
            "Epoch 00054: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1996 - acc: 0.9143 - val_loss: 0.4675 - val_acc: 0.8275\n",
            "Epoch 55/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9150\n",
            "Epoch 00055: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1983 - acc: 0.9150 - val_loss: 0.4681 - val_acc: 0.8278\n",
            "Epoch 56/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9153\n",
            "Epoch 00056: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1982 - acc: 0.9152 - val_loss: 0.4773 - val_acc: 0.8237\n",
            "Epoch 57/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9155\n",
            "Epoch 00057: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1965 - acc: 0.9155 - val_loss: 0.4820 - val_acc: 0.8281\n",
            "Epoch 58/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9156\n",
            "Epoch 00058: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1972 - acc: 0.9156 - val_loss: 0.4804 - val_acc: 0.8250\n",
            "Epoch 59/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9159\n",
            "Epoch 00059: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1958 - acc: 0.9159 - val_loss: 0.4831 - val_acc: 0.8278\n",
            "Epoch 60/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9160\n",
            "Epoch 00060: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1961 - acc: 0.9160 - val_loss: 0.4799 - val_acc: 0.8278\n",
            "Epoch 61/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9161\n",
            "Epoch 00061: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1952 - acc: 0.9161 - val_loss: 0.4869 - val_acc: 0.8260\n",
            "Epoch 62/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9167\n",
            "Epoch 00062: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1942 - acc: 0.9167 - val_loss: 0.4742 - val_acc: 0.8254\n",
            "Epoch 63/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9168\n",
            "Epoch 00063: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1935 - acc: 0.9168 - val_loss: 0.4904 - val_acc: 0.8277\n",
            "Epoch 64/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9170\n",
            "Epoch 00064: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1931 - acc: 0.9171 - val_loss: 0.4977 - val_acc: 0.8272\n",
            "Epoch 65/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9173\n",
            "Epoch 00065: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1926 - acc: 0.9173 - val_loss: 0.4968 - val_acc: 0.8266\n",
            "Epoch 66/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9175\n",
            "Epoch 00066: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1920 - acc: 0.9175 - val_loss: 0.4988 - val_acc: 0.8248\n",
            "Epoch 67/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9176\n",
            "Epoch 00067: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1922 - acc: 0.9176 - val_loss: 0.4857 - val_acc: 0.8259\n",
            "Epoch 68/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9178\n",
            "Epoch 00068: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1917 - acc: 0.9178 - val_loss: 0.4946 - val_acc: 0.8250\n",
            "Epoch 69/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9181\n",
            "Epoch 00069: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1910 - acc: 0.9182 - val_loss: 0.4990 - val_acc: 0.8251\n",
            "Epoch 70/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9185\n",
            "Epoch 00070: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1902 - acc: 0.9185 - val_loss: 0.5028 - val_acc: 0.8268\n",
            "Epoch 71/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9186\n",
            "Epoch 00071: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1897 - acc: 0.9186 - val_loss: 0.5008 - val_acc: 0.8253\n",
            "Epoch 72/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9190\n",
            "Epoch 00072: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1895 - acc: 0.9190 - val_loss: 0.4944 - val_acc: 0.8258\n",
            "Epoch 73/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9196\n",
            "Epoch 00073: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1884 - acc: 0.9196 - val_loss: 0.4992 - val_acc: 0.8247\n",
            "Epoch 74/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9192\n",
            "Epoch 00074: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1887 - acc: 0.9192 - val_loss: 0.4940 - val_acc: 0.8281\n",
            "Epoch 75/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1880 - acc: 0.9199\n",
            "Epoch 00075: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1879 - acc: 0.9199 - val_loss: 0.5001 - val_acc: 0.8274\n",
            "Epoch 76/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9196\n",
            "Epoch 00076: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1883 - acc: 0.9196 - val_loss: 0.5120 - val_acc: 0.8246\n",
            "Epoch 77/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9202\n",
            "Epoch 00077: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1868 - acc: 0.9202 - val_loss: 0.5070 - val_acc: 0.8255\n",
            "Epoch 78/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9203\n",
            "Epoch 00078: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1865 - acc: 0.9204 - val_loss: 0.5120 - val_acc: 0.8253\n",
            "Epoch 79/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9211\n",
            "Epoch 00079: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1857 - acc: 0.9210 - val_loss: 0.5127 - val_acc: 0.8247\n",
            "Epoch 80/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9203\n",
            "Epoch 00080: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1860 - acc: 0.9203 - val_loss: 0.5032 - val_acc: 0.8271\n",
            "Epoch 81/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9209\n",
            "Epoch 00081: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1857 - acc: 0.9209 - val_loss: 0.5114 - val_acc: 0.8251\n",
            "Epoch 82/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9210\n",
            "Epoch 00082: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1850 - acc: 0.9210 - val_loss: 0.5152 - val_acc: 0.8270\n",
            "Epoch 83/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9214\n",
            "Epoch 00083: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1846 - acc: 0.9214 - val_loss: 0.5183 - val_acc: 0.8266\n",
            "Epoch 84/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9212\n",
            "Epoch 00084: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1841 - acc: 0.9213 - val_loss: 0.5096 - val_acc: 0.8250\n",
            "Epoch 85/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9217\n",
            "Epoch 00085: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1837 - acc: 0.9217 - val_loss: 0.5131 - val_acc: 0.8263\n",
            "Epoch 86/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1837 - acc: 0.9216\n",
            "Epoch 00086: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1838 - acc: 0.9216 - val_loss: 0.5162 - val_acc: 0.8246\n",
            "Epoch 87/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9219\n",
            "Epoch 00087: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1833 - acc: 0.9219 - val_loss: 0.5206 - val_acc: 0.8264\n",
            "Epoch 88/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9220\n",
            "Epoch 00088: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1825 - acc: 0.9221 - val_loss: 0.5208 - val_acc: 0.8251\n",
            "Epoch 89/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9221\n",
            "Epoch 00089: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1825 - acc: 0.9221 - val_loss: 0.5114 - val_acc: 0.8239\n",
            "Epoch 90/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9222\n",
            "Epoch 00090: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1826 - acc: 0.9222 - val_loss: 0.5211 - val_acc: 0.8233\n",
            "Epoch 91/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9224\n",
            "Epoch 00091: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1821 - acc: 0.9224 - val_loss: 0.5248 - val_acc: 0.8254\n",
            "Epoch 92/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9225\n",
            "Epoch 00092: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1817 - acc: 0.9226 - val_loss: 0.5185 - val_acc: 0.8245\n",
            "Epoch 93/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9231\n",
            "Epoch 00093: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1809 - acc: 0.9231 - val_loss: 0.5307 - val_acc: 0.8262\n",
            "Epoch 94/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9226\n",
            "Epoch 00094: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1810 - acc: 0.9227 - val_loss: 0.5230 - val_acc: 0.8237\n",
            "Epoch 95/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9226\n",
            "Epoch 00095: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1813 - acc: 0.9226 - val_loss: 0.5231 - val_acc: 0.8231\n",
            "Epoch 96/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9229\n",
            "Epoch 00096: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1808 - acc: 0.9229 - val_loss: 0.5304 - val_acc: 0.8256\n",
            "Epoch 97/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9233\n",
            "Epoch 00097: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1800 - acc: 0.9233 - val_loss: 0.5248 - val_acc: 0.8237\n",
            "Epoch 98/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9236\n",
            "Epoch 00098: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1795 - acc: 0.9237 - val_loss: 0.5361 - val_acc: 0.8246\n",
            "Epoch 99/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9237\n",
            "Epoch 00099: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1793 - acc: 0.9237 - val_loss: 0.5273 - val_acc: 0.8258\n",
            "Epoch 100/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9240\n",
            "Epoch 00100: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1785 - acc: 0.9240 - val_loss: 0.5271 - val_acc: 0.8269\n",
            "Epoch 101/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9237\n",
            "Epoch 00101: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1792 - acc: 0.9237 - val_loss: 0.5270 - val_acc: 0.8240\n",
            "Epoch 102/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9238\n",
            "Epoch 00102: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1785 - acc: 0.9238 - val_loss: 0.5342 - val_acc: 0.8258\n",
            "Epoch 103/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9243\n",
            "Epoch 00103: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1782 - acc: 0.9243 - val_loss: 0.5337 - val_acc: 0.8244\n",
            "Epoch 104/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9236\n",
            "Epoch 00104: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1786 - acc: 0.9236 - val_loss: 0.5305 - val_acc: 0.8255\n",
            "Epoch 105/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9248\n",
            "Epoch 00105: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1773 - acc: 0.9248 - val_loss: 0.5311 - val_acc: 0.8267\n",
            "Epoch 106/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9245\n",
            "Epoch 00106: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1772 - acc: 0.9245 - val_loss: 0.5268 - val_acc: 0.8242\n",
            "Epoch 107/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9249\n",
            "Epoch 00107: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1767 - acc: 0.9249 - val_loss: 0.5384 - val_acc: 0.8242\n",
            "Epoch 108/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9249\n",
            "Epoch 00108: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1766 - acc: 0.9249 - val_loss: 0.5392 - val_acc: 0.8209\n",
            "Epoch 109/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9245\n",
            "Epoch 00109: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1770 - acc: 0.9245 - val_loss: 0.5283 - val_acc: 0.8246\n",
            "Epoch 110/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9250\n",
            "Epoch 00110: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1764 - acc: 0.9250 - val_loss: 0.5319 - val_acc: 0.8250\n",
            "Epoch 111/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9253\n",
            "Epoch 00111: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1759 - acc: 0.9253 - val_loss: 0.5346 - val_acc: 0.8274\n",
            "Epoch 112/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9252\n",
            "Epoch 00112: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1756 - acc: 0.9252 - val_loss: 0.5489 - val_acc: 0.8256\n",
            "Epoch 113/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9252\n",
            "Epoch 00113: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1757 - acc: 0.9252 - val_loss: 0.5334 - val_acc: 0.8257\n",
            "Epoch 114/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9249\n",
            "Epoch 00114: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1755 - acc: 0.9250 - val_loss: 0.5401 - val_acc: 0.8253\n",
            "Epoch 115/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9255\n",
            "Epoch 00115: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1754 - acc: 0.9255 - val_loss: 0.5388 - val_acc: 0.8260\n",
            "Epoch 116/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9257\n",
            "Epoch 00116: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1750 - acc: 0.9257 - val_loss: 0.5464 - val_acc: 0.8234\n",
            "Epoch 117/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9260\n",
            "Epoch 00117: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1742 - acc: 0.9260 - val_loss: 0.5444 - val_acc: 0.8245\n",
            "Epoch 118/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9256\n",
            "Epoch 00118: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1749 - acc: 0.9256 - val_loss: 0.5572 - val_acc: 0.8242\n",
            "Epoch 119/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9263\n",
            "Epoch 00119: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1735 - acc: 0.9263 - val_loss: 0.5366 - val_acc: 0.8210\n",
            "Epoch 120/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9258\n",
            "Epoch 00120: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1743 - acc: 0.9258 - val_loss: 0.5488 - val_acc: 0.8241\n",
            "Epoch 121/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9261\n",
            "Epoch 00121: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1735 - acc: 0.9261 - val_loss: 0.5446 - val_acc: 0.8239\n",
            "Epoch 122/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9264\n",
            "Epoch 00122: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1735 - acc: 0.9264 - val_loss: 0.5424 - val_acc: 0.8223\n",
            "Epoch 123/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9266\n",
            "Epoch 00123: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1728 - acc: 0.9266 - val_loss: 0.5500 - val_acc: 0.8241\n",
            "Epoch 124/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9262\n",
            "Epoch 00124: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1733 - acc: 0.9262 - val_loss: 0.5495 - val_acc: 0.8237\n",
            "Epoch 125/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9270\n",
            "Epoch 00125: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 125us/sample - loss: 0.1724 - acc: 0.9270 - val_loss: 0.5540 - val_acc: 0.8262\n",
            "Epoch 126/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9269\n",
            "Epoch 00126: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1727 - acc: 0.9269 - val_loss: 0.5503 - val_acc: 0.8245\n",
            "Epoch 127/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9265\n",
            "Epoch 00127: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1725 - acc: 0.9266 - val_loss: 0.5496 - val_acc: 0.8236\n",
            "Epoch 128/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9269\n",
            "Epoch 00128: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1726 - acc: 0.9269 - val_loss: 0.5456 - val_acc: 0.8222\n",
            "Epoch 129/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9267\n",
            "Epoch 00129: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1722 - acc: 0.9267 - val_loss: 0.5484 - val_acc: 0.8236\n",
            "Epoch 130/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9269\n",
            "Epoch 00130: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1712 - acc: 0.9269 - val_loss: 0.5617 - val_acc: 0.8263\n",
            "Epoch 131/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9271\n",
            "Epoch 00131: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 128us/sample - loss: 0.1713 - acc: 0.9271 - val_loss: 0.5775 - val_acc: 0.8238\n",
            "Epoch 132/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9271\n",
            "Epoch 00132: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1716 - acc: 0.9271 - val_loss: 0.5533 - val_acc: 0.8248\n",
            "Epoch 133/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9268\n",
            "Epoch 00133: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1716 - acc: 0.9268 - val_loss: 0.5575 - val_acc: 0.8236\n",
            "Epoch 134/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9269\n",
            "Epoch 00134: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1717 - acc: 0.9269 - val_loss: 0.5605 - val_acc: 0.8240\n",
            "Epoch 135/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9274\n",
            "Epoch 00135: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1708 - acc: 0.9274 - val_loss: 0.5572 - val_acc: 0.8228\n",
            "Epoch 136/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9274\n",
            "Epoch 00136: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1704 - acc: 0.9275 - val_loss: 0.5674 - val_acc: 0.8263\n",
            "Epoch 137/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9271\n",
            "Epoch 00137: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1710 - acc: 0.9271 - val_loss: 0.5613 - val_acc: 0.8234\n",
            "Epoch 138/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9272\n",
            "Epoch 00138: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1713 - acc: 0.9272 - val_loss: 0.5728 - val_acc: 0.8248\n",
            "Epoch 139/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9277\n",
            "Epoch 00139: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1703 - acc: 0.9277 - val_loss: 0.5558 - val_acc: 0.8231\n",
            "Epoch 140/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9286\n",
            "Epoch 00140: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1693 - acc: 0.9286 - val_loss: 0.5720 - val_acc: 0.8253\n",
            "Epoch 141/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9276\n",
            "Epoch 00141: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1700 - acc: 0.9277 - val_loss: 0.5602 - val_acc: 0.8253\n",
            "Epoch 142/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9284\n",
            "Epoch 00142: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1689 - acc: 0.9284 - val_loss: 0.5717 - val_acc: 0.8259\n",
            "Epoch 143/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9278\n",
            "Epoch 00143: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1696 - acc: 0.9278 - val_loss: 0.5611 - val_acc: 0.8236\n",
            "Epoch 144/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9284\n",
            "Epoch 00144: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1689 - acc: 0.9283 - val_loss: 0.5655 - val_acc: 0.8254\n",
            "Epoch 145/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9280\n",
            "Epoch 00145: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1697 - acc: 0.9280 - val_loss: 0.5652 - val_acc: 0.8238\n",
            "Epoch 146/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9279\n",
            "Epoch 00146: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1695 - acc: 0.9279 - val_loss: 0.5648 - val_acc: 0.8260\n",
            "Epoch 147/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9285\n",
            "Epoch 00147: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1687 - acc: 0.9285 - val_loss: 0.5550 - val_acc: 0.8246\n",
            "Epoch 148/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9285\n",
            "Epoch 00148: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1686 - acc: 0.9285 - val_loss: 0.5670 - val_acc: 0.8269\n",
            "Epoch 149/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9283\n",
            "Epoch 00149: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 126us/sample - loss: 0.1685 - acc: 0.9283 - val_loss: 0.5745 - val_acc: 0.8281\n",
            "Epoch 150/150\n",
            "149760/150000 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9282\n",
            "Epoch 00150: val_acc did not improve from 0.84059\n",
            "150000/150000 [==============================] - 19s 127us/sample - loss: 0.1691 - acc: 0.9282 - val_loss: 0.5580 - val_acc: 0.8269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76EtBzIJsfJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T9qKNfNsuTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, recall_ax = plt.subplots()\n",
        "\n",
        "\n",
        "recall_ax.plot(hist.history['recall'], 'y', label='recall')\n",
        "recall_ax.plot(hist.history['val_recall'], 'r', label='valid recall')\n",
        "\n",
        "recall_ax.plot(hist.history['f1score'], 'b', label='f1score')\n",
        "recall_ax.plot(hist.history['val_f1score'], 'g', label='valid f1score')\n",
        "\n",
        "recall_ax.plot(hist.history['precision'], 'c', label='precision')\n",
        "recall_ax.plot(hist.history['val_precision'], 'k', label='valid precision')\n",
        "\n",
        "recall_ax.set_xlabel('epoch')\n",
        "recall_ax.set_ylabel('score')\n",
        "\n",
        "recall_ax.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-K9Y2vFN2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  classifier.load_weights(\"/content/drive/My Drive/models/deeperppddbest.h5\")\n",
        "  testresult=classifier.predict(test_matrix)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2XAN8kzN3gp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "551f745f-f64c-49d9-a595-aaee0abb5900"
      },
      "source": [
        "print(testresult)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0520255  0.04725242 0.06422505 ... 0.22541031 0.13303784 0.08977461]\n",
            " [0.8743255  0.0428139  0.05168912 ... 0.08904213 0.07070249 0.04728562]\n",
            " [0.06394652 0.04105222 0.04254055 ... 0.14287636 0.07774505 0.04171047]\n",
            " ...\n",
            " [0.91817886 0.9472953  0.04020622 ... 0.03975582 0.15174589 0.03289729]\n",
            " [0.89631355 0.9194241  0.05759662 ... 0.06776044 0.37178284 0.0566242 ]\n",
            " [0.03227803 0.15996751 0.03780636 ... 0.13953447 0.61530125 0.05385279]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFucJZONFnqX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "50ec5146-d919-431b-9902-502a1104828b"
      },
      "source": [
        "def get_tag_results(testresult,test_label2):  \n",
        "  classnum={}\n",
        "  testnum={}\n",
        "  resultmat=[]\n",
        "  bestmat=[]\n",
        "  for i in range(len(testresult)):\n",
        "    eval_result=[0 for i in range(13)]\n",
        "    best_result=[0 for i in range(13)]\n",
        "    class_num=np.count_nonzero(test_label2[i]==1)+1\n",
        "    classidx=(-testresult[i]).argsort()[:class_num]\n",
        "    for k,j in enumerate(classidx):\n",
        "      if (k==0):\n",
        "        best_result[j]=1\n",
        "      eval_result[j]=1\n",
        "    resultmat.append(eval_result)\n",
        "    bestmat.append(best_result)\n",
        "    test_result2=copy.deepcopy(testresult)\n",
        "    test_result2[np.where(test_result2>0.30)]=1\n",
        "    test_result2[np.where(test_result2<=0.30)]=0\n",
        "  resultmat=np.array(resultmat)\n",
        "  bestmat=np.array(bestmat)\n",
        "  testidx=mlb.inverse_transform(resultmat)\n",
        "  classidx=mlb.inverse_transform(test_label2)\n",
        "  testidx2=mlb.inverse_transform(test_result2)\n",
        "  bestidx=mlb.inverse_transform(bestmat)\n",
        "  for i in range(len(testidx)):  \n",
        "    #print(bestidx[i],testidx2[i],testidx[i], classidx[i],i) # 값이 0.30 이상인 set, 원래 Label보다 1개 많이 보여주는 내림차순 set, 원래 label set 순서이다. \n",
        "    for classes in classidx[i]:\n",
        "      if (classes not in classnum):\n",
        "        classnum[classes]=1\n",
        "      else:\n",
        "        classnum[classes]+=1\n",
        "    for classes in testidx[i]:\n",
        "      if (classes not in testnum):\n",
        "        testnum[classes]=1\n",
        "      else:\n",
        "        testnum[classes]+=1\n",
        "  print(classnum, testnum)\n",
        "  return bestidx, testidx2, testidx, classidx#가장 높은거, 0.30이상인 set, 원래의 Label보다 1개 많이 보여주는 내림차순, 원래 Label\n",
        "\"\"\"\n",
        "best=get_tag_results(testresult,test_label2)[0]\n",
        "print(best)\n",
        "\"\"\""
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nbest=get_tag_results(testresult,test_label2)[0]\\nprint(best)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKJiCvrXd5NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "H = test_matrix[700].reshape(24,24) #위에 출력에서 나온 숫자 test_matrix['요기']에 적고 출력하면 나옴\n",
        "fig = plt.figure(figsize=(6, 3.2))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title('colorMap')\n",
        "plt.imshow(H)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
        "cax.get_xaxis().set_visible(False)\n",
        "cax.get_yaxis().set_visible(False)\n",
        "cax.patch.set_alpha(0)\n",
        "cax.set_frame_on(False)\n",
        "plt.colorbar(orientation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1UAO1g3lELo",
        "colab_type": "text"
      },
      "source": [
        "여기부터 GAN의 구현을 해봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgsQdsiqlC9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q imageio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27spffKwmnaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "\n",
        "from IPython import display"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGCuBMQI7sX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_best_results(testresult,test_label2):  #for optimizing.\n",
        "  classnum={}\n",
        "  testnum={}\n",
        "  resultmat=[]\n",
        "  bestmat=[]\n",
        "  for i in range(len(testresult)):\n",
        "    best_result=[0 for i in range(13)]\n",
        "    class_num=np.count_nonzero(test_label2[i]==1)+1\n",
        "    classidx=(-testresult[i]).argsort()[:class_num]\n",
        "    for k,j in enumerate(classidx):\n",
        "      if (k==0):\n",
        "        best_result[j]=1\n",
        "    bestmat.append(best_result)\n",
        "  bestmat=np.array(bestmat)\n",
        "  bestidx=mlb.inverse_transform(bestmat)\n",
        "  return bestidx"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V32sqv0MOOnI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52044c43-1f99-4fa4-85ca-d49fc6b0be90"
      },
      "source": [
        "trainX=train_matrix.reshape((150000,24,24))\n",
        "for i in tqdm(range(150),position=0):\n",
        "  if(i==0):\n",
        "    test_result=classifier.predict(train_matrix[1000*i:1000+1000*i])\n",
        "  else:\n",
        "    sub_testresult=classifier.predict(train_matrix[1000*i:1000+1000*i])\n",
        "    test_result=np.concatenate((test_result,sub_testresult))\n",
        "trainy=np.array(get_best_results(test_result,train_label2)).reshape((150000,))\n",
        "print('Train', trainX.shape, trainy.shape)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 150/150 [00:09<00:00, 16.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train (150000, 24, 24) (150000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCe1Clvjvz1-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8494f87-5e88-4810-a773-6505941c369c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# 라벨 인코더 생성\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# X_train데이터를 이용 피팅하고 라벨숫자로 변환한다\n",
        "encoder.fit(trainy)\n",
        "trainy = encoder.transform(trainy)\n",
        "print(trainy)\n",
        "trainy=np.array(trainy)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 3 5 ... 7 0 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiRvfSRjmyEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.ndimage\n",
        "def blur_image(matrix):\n",
        "  sigma_y = 1.0\n",
        "  sigma_x = 1.0\n",
        "  inputmat=matrix\n",
        "  \"\"\"\n",
        "  # Plot input array\n",
        "  plt.imshow(inputmat, cmap='Blues', interpolation='nearest')\n",
        "  plt.xlabel(\"$x$\")\n",
        "  plt.ylabel(\"$y$\")\n",
        "  plt.savefig(\"array.png\")\n",
        "  \"\"\"\n",
        "  # Apply gaussian filter\n",
        "  sigma = [sigma_y, sigma_x]\n",
        "  y = sp.ndimage.filters.gaussian_filter(inputmat, sigma, mode='constant')\n",
        "  \"\"\"\n",
        "  # Display filtered array\n",
        "  plt.imshow(y, cmap='Blues', interpolation='nearest')\n",
        "  plt.xlabel(\"$x$\")\n",
        "  plt.ylabel(\"$y$\")\n",
        "  plt.title(\"$\\sigma_x = \" + str(sigma_x) + \"\\quad \\sigma_y = \" + str(sigma_y) + \"$\")\n",
        "  plt.savefig(\"smooth_array_\" + str(sigma_x) + \"_\" + str(sigma_y) + \".png\")\n",
        "  \"\"\"\n",
        "  return y\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHYRcDkY4GgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blur_trainX=copy.deepcopy(trainX)\n",
        "for i,matrix in enumerate(trainX):\n",
        "  blur_trainX[i]=blur_image(matrix)\n",
        "trainX=blur_trainX"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJr2T_F3wHVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/gaborvecsei/CDCGAN-Keras/tree/master/cdcgan\n",
        "#위 깃헙의 코드를 사용하는겁니다\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "from keras import models, layers\n",
        "\n",
        "ACTIVATION = layers.Activation(\"tanh\")\n",
        "\n",
        "\n",
        "def generator_model():\n",
        "  with tf.device('/gpu:0'):\n",
        "    # Prepare noise input\n",
        "    input_z = layers.Input((13,))\n",
        "    dense_z_1 = layers.Dense(1024)(input_z)\n",
        "    act_z_1 = ACTIVATION(dense_z_1)\n",
        "    dense_z_2 = layers.Dense(128 * 6* 6)(act_z_1)\n",
        "    bn_z_1 = layers.BatchNormalization()(dense_z_2)\n",
        "    reshape_z = layers.Reshape((6, 6, 128), input_shape=(128 * 6 * 6,))(bn_z_1)\n",
        "\n",
        "    # Prepare Conditional (label) input\n",
        "    input_c = layers.Input((13,))\n",
        "    dense_c_1 = layers.Dense(1024)(input_c)\n",
        "    act_c_1 = ACTIVATION(dense_c_1)\n",
        "    dense_c_2 = layers.Dense(128 * 6 * 6)(act_c_1)\n",
        "    bn_c_1 = layers.BatchNormalization()(dense_c_2)\n",
        "    reshape_c = layers.Reshape((6, 6, 128), input_shape=(128 * 6 * 6,))(bn_c_1)\n",
        "\n",
        "    # Combine input source\n",
        "    concat_z_c = layers.Concatenate()([reshape_z, reshape_c])\n",
        "\n",
        "    # Image generation with the concatenated inputs\n",
        "    up_1 = layers.UpSampling2D(size=(2, 2))(concat_z_c)\n",
        "    conv_1 = layers.Conv2D(64, (5, 5), padding='same')(up_1)\n",
        "    act_1 = ACTIVATION(conv_1)\n",
        "    up_2 = layers.UpSampling2D(size=(2, 2))(act_1)\n",
        "    conv_2 = layers.Conv2D(1, (5, 5), padding='same')(up_2)\n",
        "    act_2 = layers.Activation(\"tanh\")(conv_2)\n",
        "    model = models.Model(inputs=[input_z, input_c], outputs=act_2)\n",
        "    return model\n",
        "\n",
        "\n",
        "def discriminator_model():\n",
        "  with tf.device('/gpu:0'):\n",
        "    input_gen_image = layers.Input((24, 24, 1))\n",
        "    conv_1_image = layers.Conv2D(64, (5, 5), padding='same')(input_gen_image)\n",
        "    act_1_image = ACTIVATION(conv_1_image)\n",
        "    pool_1_image = layers.MaxPooling2D(pool_size=(2, 2))(act_1_image)\n",
        "    conv_2_image = layers.Conv2D(128, (5, 5))(pool_1_image)\n",
        "    act_2_image = ACTIVATION(conv_2_image)\n",
        "    pool_2_image = layers.MaxPooling2D(pool_size=(2, 2))(act_2_image)\n",
        "\n",
        "    input_c = layers.Input((13,))\n",
        "    dense_1_c = layers.Dense(1024)(input_c)\n",
        "    act_1_c = ACTIVATION(dense_1_c)\n",
        "    dense_2_c = layers.Dense(4 * 4 * 128)(act_1_c)\n",
        "    bn_c = layers.BatchNormalization()(dense_2_c)\n",
        "    reshaped_c = layers.Reshape((4, 4, 128))(bn_c)\n",
        "\n",
        "    concat = layers.Concatenate()([pool_2_image, reshaped_c])\n",
        "\n",
        "    flat = layers.Flatten()(concat)\n",
        "    dense_1 = layers.Dense(1024)(flat)\n",
        "    act_1 = ACTIVATION(dense_1)\n",
        "    dense_2 = layers.Dense(1)(act_1)\n",
        "    act_2 = layers.Activation('sigmoid')(dense_2)\n",
        "    model = models.Model(inputs=[input_gen_image, input_c], outputs=act_2)\n",
        "    return model\n",
        "\n",
        "\n",
        "def generator_containing_discriminator(g, d):\n",
        "  with tf.device('/gpu:0'):\n",
        "    input_z = layers.Input((13,))\n",
        "    input_c = layers.Input((13,))\n",
        "    gen_image = g([input_z, input_c])\n",
        "    d.trainable = False\n",
        "    is_real = d([gen_image, input_c])\n",
        "    model = models.Model(inputs=[input_z, input_c], outputs=is_real)\n",
        "    return model"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNHFwwLpm85B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def combine_images(generated_images):\n",
        "    num_images = generated_images.shape[0]\n",
        "    new_width = int(math.sqrt(num_images))\n",
        "    new_height = int(math.ceil(float(num_images) / new_width))\n",
        "    grid_shape = generated_images.shape[1:3]\n",
        "    grid_image = np.zeros((new_height * grid_shape[0], new_width * grid_shape[1]), dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index / new_width)\n",
        "        j = index % new_width\n",
        "        grid_image[i * grid_shape[0]:(i + 1) * grid_shape[0], j * grid_shape[1]:(j + 1) * grid_shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return grid_image\n",
        "\n",
        "\n",
        "def generate_noise(shape: tuple):\n",
        "    noise = np.random.uniform(0, 1, size=shape)\n",
        "    return noise\n",
        "\n",
        "\n",
        "def generate_condition_embedding(label: int, nb_of_label_embeddings: int):\n",
        "    label_embeddings = np.zeros((nb_of_label_embeddings, 13))\n",
        "    label_embeddings[:, label] = 1\n",
        "    return label_embeddings\n",
        "\n",
        "\n",
        "def generate_images(generator, nb_images: int, label: int):\n",
        "    noise = generate_noise((nb_images, 13))\n",
        "    label_batch = generate_condition_embedding(label, nb_images)\n",
        "    generated_images = generator.predict([noise, label_batch], verbose=0)\n",
        "    return generated_images\n",
        "\n",
        "\n",
        "def generate_mnist_image_grid(generator, title: str = \"Generated images\"):\n",
        "    generated_images = []\n",
        "\n",
        "    for i in range(10):\n",
        "        noise = generate_noise((10, 13))\n",
        "        label_input = generate_condition_embedding(i, 10)\n",
        "        gen_images = generator.predict([noise, label_input], verbose=0)\n",
        "        generated_images.extend(gen_images)\n",
        "\n",
        "    generated_images = np.array(generated_images)\n",
        "    image_grid = combine_images(generated_images)\n",
        "    image_grid = inverse_transform_images(image_grid)\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.imshow(image_grid, cmap=\"gray\")\n",
        "    ax.set_title(title)\n",
        "    fig.canvas.draw()\n",
        "\n",
        "    image = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')\n",
        "    image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def save_generated_image(image, epoch, iteration, folder_path):\n",
        "    if not os.path.isdir(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "\n",
        "    file_path = \"{0}/{1}_{2}.png\".format(folder_path, epoch, iteration)\n",
        "    cv2.imwrite(file_path, image.astype(np.uint8))\n",
        "\n",
        "\n",
        "def transform_images(images: np.ndarray):\n",
        "    \"\"\"\n",
        "    [0,1]Transform images to [-1, 1]\n",
        "    \"\"\"\n",
        "    max_value=images.max()\n",
        "\n",
        "    images = (images.astype(np.float32) - (max_value/2)) / (max_value/2)\n",
        "    return images\n",
        "\n",
        "\n",
        "def inverse_transform_images(images: np.ndarray):\n",
        "    \"\"\"\n",
        "    From the [-1, 1] range transform the images back to [0, 255]\n",
        "    \"\"\"\n",
        "\n",
        "    images = images * 127.5 + 127.5\n",
        "    images = images.astype(np.uint8)\n",
        "    return images\n",
        "\n",
        "\n",
        "def convert_video_to_gif(input_video_path, output_gif_path, fps=24):\n",
        "    palette_image_path = \"palette.png\"\n",
        "    command_palette = 'ffmpeg -y -t 0 -i {0} -vf fps={1},scale=320:-1:flags=lanczos,palettegen {2}'.format(input_video_path,\n",
        "                                                                                                           fps,\n",
        "                                                                                                           palette_image_path)\n",
        "    command_convert = 'ffmpeg -y -t 0 -i {0} -i {1} -filter_complex \"fps={2},scale=320:-1:flags=lanczos[x];[x][1:v]paletteuse\" {3}'.format(input_video_path,palette_image_path, fps, output_gif_path)\n",
        "    \n",
        "    try:\n",
        "        subprocess.check_call(command_palette)\n",
        "        subprocess.check_call(command_convert)\n",
        "    except subprocess.CalledProcessError as exc:\n",
        "        print(exc.output)\n",
        "        raise\n",
        "    finally:\n",
        "        os.remove(palette_image_path)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xqJAsQDYM2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "22a0200c-6f5f-450d-c4f3-fe5dd802cfab"
      },
      "source": [
        "pip install git+https://github.com/gaborvecsei/Swiss-Army-Tensorboard.git"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/gaborvecsei/Swiss-Army-Tensorboard.git\n",
            "  Cloning https://github.com/gaborvecsei/Swiss-Army-Tensorboard.git to /tmp/pip-req-build-op2wvc9z\n",
            "  Running command git clone -q https://github.com/gaborvecsei/Swiss-Army-Tensorboard.git /tmp/pip-req-build-op2wvc9z\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from swiss-army-tensorboard==0.0.1) (1.18.5)\n",
            "Requirement already satisfied: matplotlib>=3.1 in /usr/local/lib/python3.6/dist-packages (from swiss-army-tensorboard==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->swiss-army-tensorboard==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->swiss-army-tensorboard==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->swiss-army-tensorboard==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1->swiss-army-tensorboard==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=3.1->swiss-army-tensorboard==0.0.1) (1.15.0)\n",
            "Building wheels for collected packages: swiss-army-tensorboard\n",
            "  Building wheel for swiss-army-tensorboard (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for swiss-army-tensorboard: filename=swiss_army_tensorboard-0.0.1-cp36-none-any.whl size=5377 sha256=c0a3bed04084716092b3f5bd86204d7d393774957d4f275d05c06816e6896715\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xhnuokk_/wheels/ea/f7/db/67f8661f9c334ad8eda2d0dfbc21bcaea99f739c97f6008d41\n",
            "Successfully built swiss-army-tensorboard\n",
            "Installing collected packages: swiss-army-tensorboard\n",
            "Successfully installed swiss-army-tensorboard-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJjHn-Nngy8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b47e2152-382b-4f3a-9953-1711b811e9af"
      },
      "source": [
        "import matplotlib\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras import utils as keras_utils\n",
        "from keras import optimizers\n",
        "from keras import datasets\n",
        "from swiss_army_tensorboard import tfboard_loggers\n",
        "from tqdm import tqdm\n",
        "#from cdcgan import cdcgan_models, cdcgan_utils\n",
        "#colab환경이라 안씁니다\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n",
        "\n",
        "# Load & Prepare MNIST\n",
        "\n",
        "X_train=trainX\n",
        "y_train=trainy\n",
        "X_train = transform_images(X_train)\n",
        "X_train = X_train[:, :, :, None]\n",
        "\n",
        "y_train = keras_utils.to_categorical(y_train, 13) #원래는 13써야 하는데 추후 고려할 예정\n",
        "\n",
        "# Create the models\n",
        "\n",
        "print(\"Generator:\")\n",
        "G = generator_model()\n",
        "G.summary()\n",
        "\n",
        "print(\"Discriminator:\")\n",
        "D = discriminator_model()\n",
        "D.summary()\n",
        "\n",
        "print(\"Combined:\")\n",
        "GD = generator_containing_discriminator(G, D)\n",
        "GD.summary()\n",
        "\n",
        "optimizer = optimizers.Adam(0.0002, 0.5)\n",
        "\n",
        "\n",
        "G.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "GD.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "D.trainable = True\n",
        "D.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator:\n",
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_30 (InputLayer)           (None, 13)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_31 (InputLayer)           (None, 13)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 1024)         14336       input_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 1024)         14336       input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       multiple             0           dense_33[0][0]                   \n",
            "                                                                 dense_35[0][0]                   \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 4608)         4723200     activation_1[28][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 4608)         4723200     activation_1[29][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 4608)         18432       dense_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 4608)         18432       dense_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 6, 6, 128)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 6, 6, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 6, 6, 256)    0           reshape_13[0][0]                 \n",
            "                                                                 reshape_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2D)  (None, 12, 12, 256)  0           concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 12, 12, 64)   409664      up_sampling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling2D) (None, 24, 24, 64)   0           activation_1[30][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 24, 24, 1)    1601        up_sampling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 24, 24, 1)    0           conv2d_20[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 9,923,201\n",
            "Trainable params: 9,904,769\n",
            "Non-trainable params: 18,432\n",
            "__________________________________________________________________________________________________\n",
            "Discriminator:\n",
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_32 (InputLayer)           (None, 24, 24, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 24, 24, 64)   1664        input_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       multiple             0           conv2d_21[0][0]                  \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "                                                                 dense_37[0][0]                   \n",
            "                                                                 dense_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 64)   0           activation_1[31][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_33 (InputLayer)           (None, 13)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 128)    204928      max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 1024)         14336       input_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 2048)         2099200     activation_1[33][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 2048)         8192        dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 128)    0           activation_1[32][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 4, 4, 128)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 4, 4, 256)    0           max_pooling2d_10[0][0]           \n",
            "                                                                 reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 4096)         0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 1024)         4195328     flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 1)            1025        activation_1[34][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 1)            0           dense_40[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 6,524,673\n",
            "Trainable params: 6,520,577\n",
            "Non-trainable params: 4,096\n",
            "__________________________________________________________________________________________________\n",
            "Combined:\n",
            "Model: \"model_15\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_34 (InputLayer)           (None, 13)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_35 (InputLayer)           (None, 13)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_13 (Model)                (None, 24, 24, 1)    9923201     input_34[0][0]                   \n",
            "                                                                 input_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_14 (Model)                (None, 1)            6524673     model_13[1][0]                   \n",
            "                                                                 input_35[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 16,447,874\n",
            "Trainable params: 9,904,769\n",
            "Non-trainable params: 6,543,105\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiSLW8ipuBhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G.load_weights(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generator.h5\")\n",
        "D.load_weights(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/discriminator.h5\")"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX3bvlrduAKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e6149b6-b5fd-42b2-84db-164603e52f7e"
      },
      "source": [
        "# Setup Tensorboard loggers\n",
        "\n",
        "tfboard_loggers.TFBoardModelGraphLogger.log_graph(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/logs\", K.get_session())\n",
        "loss_logger = tfboard_loggers.TFBoardScalarLogger(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/logs/loss\")\n",
        "image_logger = tfboard_loggers.TFBoardImageLogger(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/logs/generated_images\")\n",
        "\n",
        "# Model Training\n",
        "\n",
        "iteration = 0\n",
        "\n",
        "nb_of_iterations_per_epoch = int(X_train.shape[0] / BATCH_SIZE)\n",
        "print(\"Number of iterations per epoch: {0}\".format(nb_of_iterations_per_epoch))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    pbar = tqdm(desc=\"Epoch: {0}\".format(epoch), total=X_train.shape[0],position=0)\n",
        "\n",
        "    g_losses_for_epoch = []\n",
        "    d_losses_for_epoch = []\n",
        "\n",
        "    for i in range(nb_of_iterations_per_epoch):\n",
        "        noise = generate_noise((BATCH_SIZE, 13))\n",
        "\n",
        "        image_batch = X_train[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
        "        label_batch = y_train[i * BATCH_SIZE:(i + 1) * BATCH_SIZE]\n",
        "\n",
        "        generated_images = G.predict([noise, label_batch], verbose=0)\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            image_grid = generate_mnist_image_grid(G,\n",
        "                                                                title=\"Epoch {0}, iteration {1}\".format(epoch,\n",
        "                                                                                                        iteration))\n",
        "            save_generated_image(image_grid, epoch, i, \"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generated_mnist_images_per_iteration\")\n",
        "            image_logger.log_images(\"generated_mnist_images_per_iteration\", [image_grid], iteration)\n",
        "\n",
        "        X = np.concatenate((image_batch, generated_images))\n",
        "        y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
        "        label_batches_for_discriminator = np.concatenate((label_batch, label_batch))\n",
        "\n",
        "        D_loss = D.train_on_batch([X, label_batches_for_discriminator], y)\n",
        "        d_losses_for_epoch.append(D_loss)\n",
        "        loss_logger.log_scalar(\"discriminator_loss\", D_loss, iteration)\n",
        "\n",
        "        noise = generate_noise((BATCH_SIZE, 13))\n",
        "        D.trainable = False\n",
        "        G_loss = GD.train_on_batch([noise, label_batch], [1] * BATCH_SIZE)\n",
        "        D.trainable = True\n",
        "        g_losses_for_epoch.append(G_loss)\n",
        "        loss_logger.log_scalar(\"generator_loss\", G_loss, iteration)\n",
        "\n",
        "        pbar.update(BATCH_SIZE)\n",
        "\n",
        "        iteration += 1\n",
        "\n",
        "    # Save a generated image for every epoch\n",
        "    image_grid = generate_mnist_image_grid(G, title=\"Epoch {0}\".format(epoch))\n",
        "    save_generated_image(image_grid, epoch, 0, \"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generated_mnist_images_per_epoch\")\n",
        "    image_logger.log_images(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generated_mnist_images_per_epoch\", [image_grid], epoch)\n",
        "\n",
        "    pbar.close()\n",
        "    print(\"D loss: {0}, G loss: {1}\".format(np.mean(d_losses_for_epoch), np.mean(g_losses_for_epoch)))\n",
        "\n",
        "    G.save_weights(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generator.h5\")\n",
        "    D.save_weights(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/discriminator.h5\")"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/swiss_army_tensorboard/tfboard_loggers/tfboard_loggers.py:19: UserWarning: Folder /content/drive/My Drive/MARG/PPDDlist/GAN_result/logs/loss is already created, maybe it contains other log files\n",
            "  warnings.warn(\"Folder {0} is already created, maybe it contains other log files\".format(log_dir))\n",
            "/usr/local/lib/python3.6/dist-packages/swiss_army_tensorboard/tfboard_loggers/tfboard_loggers.py:19: UserWarning: Folder /content/drive/My Drive/MARG/PPDDlist/GAN_result/logs/generated_images is already created, maybe it contains other log files\n",
            "  warnings.warn(\"Folder {0} is already created, maybe it contains other log files\".format(log_dir))\n",
            "\rEpoch: 0:   0%|          | 0/150000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of iterations per epoch: 1171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "Epoch: 0:   2%|▏         | 2432/150000 [00:08<19:19, 127.28it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "Epoch: 0: 100%|█████████▉| 149888/150000 [00:53<00:00, 2810.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.5789399743080139, G loss: 0.8157476782798767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1: 100%|█████████▉| 149888/150000 [00:45<00:00, 3307.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.6164580583572388, G loss: 0.9174013733863831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2: 100%|█████████▉| 149888/150000 [00:45<00:00, 3296.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.4763569235801697, G loss: 1.0860766172409058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3: 100%|█████████▉| 149888/150000 [01:34<00:00, 1586.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.38570544123649597, G loss: 1.077909231185913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4: 100%|█████████▉| 149888/150000 [01:33<00:00, 1594.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.36611491441726685, G loss: 1.545870304107666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5: 100%|█████████▉| 149888/150000 [01:32<00:00, 1624.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.36121299862861633, G loss: 1.9583868980407715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6: 100%|█████████▉| 149888/150000 [01:33<00:00, 1605.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.34327787160873413, G loss: 2.068080186843872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7: 100%|█████████▉| 149888/150000 [01:31<00:00, 1631.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.3197210729122162, G loss: 1.7507096529006958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8: 100%|█████████▉| 149888/150000 [01:31<00:00, 1646.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.34950360655784607, G loss: 1.9752813577651978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9: 100%|█████████▉| 149888/150000 [01:32<00:00, 1627.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.320128470659256, G loss: 2.0860259532928467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10: 100%|█████████▉| 149888/150000 [01:30<00:00, 1659.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.3118766248226166, G loss: 2.2158703804016113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11: 100%|█████████▉| 149888/150000 [01:30<00:00, 1647.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.26692280173301697, G loss: 2.2465546131134033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12: 100%|█████████▉| 149888/150000 [01:32<00:00, 1612.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.26386162638664246, G loss: 2.469987154006958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13: 100%|█████████▉| 149888/150000 [01:30<00:00, 1647.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.2464246153831482, G loss: 2.6427645683288574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14: 100%|█████████▉| 149888/150000 [01:29<00:00, 1677.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.23078300058841705, G loss: 2.8333020210266113\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15: 100%|█████████▉| 149888/150000 [01:30<00:00, 1659.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.2276402860879898, G loss: 2.9623732566833496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16: 100%|█████████▉| 149888/150000 [01:30<00:00, 1650.58it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.2189774066209793, G loss: 3.053593158721924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17: 100%|█████████▉| 149888/150000 [01:30<00:00, 1648.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.20485271513462067, G loss: 3.1177616119384766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18: 100%|█████████▉| 149888/150000 [01:30<00:00, 1658.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.20247063040733337, G loss: 3.1894989013671875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19: 100%|█████████▉| 149888/150000 [01:30<00:00, 1650.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.18958759307861328, G loss: 3.299363851547241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20: 100%|█████████▉| 149888/150000 [01:29<00:00, 1680.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.17826367914676666, G loss: 3.4002158641815186\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21: 100%|█████████▉| 149888/150000 [01:29<00:00, 1673.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.16624020040035248, G loss: 3.5275206565856934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22: 100%|█████████▉| 149888/150000 [01:30<00:00, 1654.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.1976858228445053, G loss: 3.6596672534942627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23: 100%|█████████▉| 149888/150000 [01:30<00:00, 1664.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.17173609137535095, G loss: 3.4268012046813965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24: 100%|█████████▉| 149888/150000 [01:31<00:00, 1645.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.16302302479743958, G loss: 3.597255229949951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25: 100%|█████████▉| 149888/150000 [01:29<00:00, 1676.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.1615023910999298, G loss: 3.7809810638427734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26: 100%|█████████▉| 149888/150000 [01:28<00:00, 1687.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.15750212967395782, G loss: 3.9069793224334717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27: 100%|█████████▉| 149888/150000 [01:29<00:00, 1666.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "D loss: 0.14521412551403046, G loss: 3.932682991027832\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28:  20%|██        | 30464/150000 [00:17<00:47, 2500.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-130-59826f790521>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                                 title=\"Epoch {0}, iteration {1}\".format(epoch,\n\u001b[1;32m     31\u001b[0m                                                                                                         iteration))\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0msave_generated_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generated_mnist_images_per_iteration\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mimage_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generated_mnist_images_per_iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_grid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-c7ae92a2afd1>\u001b[0m in \u001b[0;36msave_generated_image\u001b[0;34m(image, epoch, iteration, folder_path)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{0}/{1}_{2}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdEukvpITK_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(trainX[i], cmap='gray_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUyKRM_Vqd9Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "9d9f8282-ca97-42de-bbfe-7ec512f85927"
      },
      "source": [
        "print(encoder.classes_)\n",
        "image=generate_images(G,10,12)\n",
        "H = image[0].reshape((24,24))\n",
        "\n",
        "fig = plt.figure(figsize=(14, 3))\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title('colorMap')\n",
        "plt.imshow(H)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
        "cax.get_xaxis().set_visible(False)\n",
        "cax.get_yaxis().set_visible(False)\n",
        "cax.patch.set_alpha(0)\n",
        "cax.set_frame_on(False)\n",
        "plt.colorbar(orientation='vertical')\n",
        "plt.show()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['One_rhythm' 'continuing_rhythm' 'down_leaping' 'down_steping'\n",
            " 'fast_rhythm' 'leaping_twisting' 'repeating' 'resting' 'staccato'\n",
            " 'steping_twisting' 'triplet' 'up_leaping' 'up_steping']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x216 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exdtcOln9Qdq",
        "colab_type": "text"
      },
      "source": [
        "여기서부터 Simple RNN을 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNqr-1ZWLKdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNNx_train=[]\n",
        "RNNy_train=[]\n",
        "RNNx_test=[]\n",
        "RNNy_test=[]\n",
        "RNN_kfoldx=[]\n",
        "RNN_kfoldy=[]\n",
        "for i in range(len(bar_matrix_list3)):\n",
        "  nowseq=[]\n",
        "  nowmat=np.array(bar_matrix_list3[i])\n",
        "  nowbars=classifier.predict(nowmat.reshape(len(nowmat),24,24,1) ) #이는 mlb를 통해 embedding 되어있다\n",
        "  for j,bars in enumerate(nowbars):\n",
        "    if(j==len(nowbars)-1):\n",
        "      if(i>5000):\n",
        "        RNNy_test.append(np.argmax(bars))\n",
        "      else:\n",
        "        RNNy_train.append(np.argmax(bars))\n",
        "      RNN_kfoldy.append(np.argmax(bars))\n",
        "    else:\n",
        "      nowseq.append(np.argmax(bars))\n",
        "  if(i>5000):\n",
        "    RNNx_test.append(nowseq)\n",
        "  else:\n",
        "    RNNx_train.append(nowseq)\n",
        "  RNN_kfoldx.append(nowseq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbnUCrqw9O2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "RNNy_test=to_categorical(np.array(RNNy_test))\n",
        "RNNy_train=to_categorical(np.array(RNNy_train))\n",
        "RNN_kfoldy=to_categorical(np.array(RNN_kfoldy))\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "top_words=13\n",
        "# truncate and pad input sequences\n",
        "max_review_length =0\n",
        "for seq in RNN_kfoldx:\n",
        "  if (len(seq)>max_review_length):\n",
        "    max_review_length=len(seq)\n",
        "RNNx_train = sequence.pad_sequences(RNNx_train, maxlen=max_review_length)\n",
        "RNNx_test = sequence.pad_sequences(RNNx_test, maxlen=max_review_length)\n",
        "RNN_kfoldx = sequence.pad_sequences(RNN_kfoldx, maxlen=max_review_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd4AzRMhPWyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "555e9c10-ee34-4d13-ea03-b3bd791aeec3"
      },
      "source": [
        "print(RNN_kfoldx.shape, RNN_kfoldy.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 107) (10000, 13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmiN9lI_fbs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "model_path = '/content/drive/My Drive/models/' + 'RNN.h5'\n",
        "\n",
        "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy',\n",
        "                                verbose=1, save_best_only=True)\n",
        "callbacks = [cb_checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtTnECWM9ooa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import regularizers\n",
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "timesteps = 8\n",
        "\n",
        "RNNmodel = Sequential()\n",
        "RNNmodel.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "RNNmodel.add(LSTM(100, return_sequences=True,\n",
        "               input_shape=(timesteps, 100)))  # returns a sequence of vectors of dimension 32\n",
        "RNNmodel.add(LSTM(100))  # return a single vector of dimension 32\n",
        "RNNmodel.add(Dropout(0.2))\n",
        "RNNmodel.add(Dense(13, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
        "\n",
        "RNNmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(RNNmodel.summary())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwd8KBt0SKZF",
        "colab_type": "text"
      },
      "source": [
        "아래거는 kfold방식. 더 아래에는 그냥 위에서 설정한 RNNmodel을 train : valid = 1:1로 학습하는 코드가 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oztvg4cPAxPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=7)\n",
        "for i in range(3):\n",
        "  for train,valid in kfold.split(RNN_kfoldx,RNN_kfoldy):\n",
        "    RNNmodel.fit(RNN_kfoldx[train],RNN_kfoldy[train], validation_data=(RNN_kfoldx[valid],RNN_kfoldy[valid]),epochs=30, batch_size=64,callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dxd0_4Judth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RNNmodel.load_weight('/content/drive/My Drive/models/RNN.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8-5W7XTuaVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist=RNNmodel.fit(RNNx_train, RNNy_train, validation_data=(RNNx_test, RNNy_test), epochs=300, batch_size=64,callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuOfuuWDZuW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upW2vW-k91lu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a749a6b6-fa9a-4675-9f00-235e605ca2e6"
      },
      "source": [
        "scores = model.evaluate(RNNx_test, RNNy_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 27.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0nHEDZOYxdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "936f810e-9337-4b9d-8f13-1c5ade3f21e8"
      },
      "source": [
        "print(model.predict(RNNx_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00058642 0.00063235 0.00212106 ... 0.00035581 0.00314277 0.00107208]\n",
            " [0.00200537 0.00039899 0.01504618 ... 0.0016143  0.00947371 0.0021562 ]\n",
            " [0.00043494 0.00076485 0.00288963 ... 0.00060204 0.00506374 0.00097767]\n",
            " ...\n",
            " [0.00398669 0.00089505 0.00564978 ... 0.00082496 0.00648937 0.00188497]\n",
            " [0.00046164 0.00052354 0.00999689 ... 0.00185463 0.00193721 0.00123206]\n",
            " [0.00154445 0.0010455  0.00651681 ... 0.00544364 0.00606789 0.00185878]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CP7tkoSCIm2",
        "colab_type": "text"
      },
      "source": [
        "classifier : 24*24 bar input을 기반하여 Skill을 분류한다. 학습은 Multilabel Classifier로써 진행된다.\n",
        "\n",
        "updown_classifier : 24*24 bar input을 기반하여 다음 bar의 pitch change를 분류한다. 학습은 up, down, final, meanless 4가지 기반하여 진행되나 분류 자체는 up, down만 유의미하다.\n",
        "\n",
        "RNNmodel : bar skill sequence를 기반하여 다음 bar가 어떤 스킬을 가지는지를 분류한다. 학습은 k-fold기반의 RNN으로 진행된다\n",
        "\n",
        "G : GAN기반한 모델의 Generator이다. image_generator(G,갯수,encoded skill num)과 같은 형태로 사용하여 이미지를 생성할 수 있다. 원할한 생성을 위해 Matrix Image에 Bluring을 사용한다.\n",
        "\n",
        "이제 G가 생성한 Matrix이미지를 0과1로 이루어진 Matrix로 정리하고, Chord를 Match시켜준 뒤 MIDI로 Decoding하면 끝이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Q__y8tCG-a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e1d5c942-e782-4f1f-d7e0-0df8d775e16d"
      },
      "source": [
        "#Model Loading Only\n",
        "RNNmodel = Sequential()\n",
        "RNNmodel.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
        "RNNmodel.add(LSTM(100, return_sequences=True,\n",
        "               input_shape=(timesteps, 100)))  # returns a sequence of vectors of dimension 32\n",
        "RNNmodel.add(LSTM(100))  # return a single vector of dimension 32\n",
        "RNNmodel.add(Dropout(0.2))\n",
        "RNNmodel.add(Dense(13, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))\n",
        "RNNmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "RNNmodel.load_weight('/content/drive/My Drive/models/RNN.h5')\n",
        "\n",
        "G = generator_model()\n",
        "G.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "G.load_weights(\"/content/drive/My Drive/MARG/PPDDlist/GAN_result/generator.h5\")\n",
        "\n",
        "updown_classifier=make_classifier()\n",
        "updown_classifier.compile(loss=keras.losses.CategoricalCrossentropy(\n",
        "      from_logits=False, label_smoothing=0.1, \n",
        "      name='categorical_crossentropy'\n",
        "  ), optimizer='adam', metrics=['accuracy'])\n",
        "updown_classifier.load_weights(\"/content/drive/My Drive/models/updown.h5\")\n",
        "\n",
        "classifier=make_model()\n",
        "classifier.compile(loss=keras.losses.BinaryCrossentropy(\n",
        "      from_logits=False, label_smoothing=0.1, \n",
        "      name='binary_crossentropy'\n",
        "  ), optimizer='adam', metrics=['accuracy',recall,precision,f1score])\n",
        "classifier.load_weights(\"/content/drive/My Drive/models/deeperppddbest.h5\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-d52597458d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model Loading Only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mRNNmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mRNNmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_vecor_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_review_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m RNNmodel.add(LSTM(100, return_sequences=True,\n\u001b[1;32m      5\u001b[0m                input_shape=(timesteps, 100)))  # returns a sequence of vectors of dimension 32\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Embedding' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6htKIS4Lcb7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "35b5895a-0008-4781-9a84-528d248e601b"
      },
      "source": [
        "import cv2\n",
        "H=generate_images(G,4,4)[0]\n",
        "def matrix_cleaner(matrix):\n",
        "  #matrix should be size of 24*24\n",
        "  #make matrix's value of [0,1]  \n",
        "  matrix=np.matrix(matrix)\n",
        "  maximum_value=matrix.max()\n",
        "  minimum_value=matrix.min()\n",
        "  matrix=(matrix-minimum_value)/(maximum_value-minimum_value)\n",
        "  flat=matrix.flatten()\n",
        "  flat.sort()\n",
        "  flat=flat.reshape((576,1))\n",
        "  hundred_val=flat[-70]\n",
        "  matrix=np.where(matrix<hundred_val,0,matrix)\n",
        "  matrix=np.where(matrix<0.3,0,matrix)\n",
        "  return matrix\n",
        "plt.imshow(matrix_cleaner(H))"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2de4bc47b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRSy54CpFDz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "dd6dbd53-31f2-40ea-d3a4-00065be77e88"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage.filters import maximum_filter\n",
        "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion\n",
        "import matplotlib.pyplot as pp\n",
        "\n",
        "#getting a list of images\n",
        "\n",
        "paws = [matrix_cleaner(H)]\n",
        "\n",
        "\n",
        "def detect_peaks(image):\n",
        "    \"\"\"\n",
        "    Takes an image and detect the peaks usingthe local maximum filter.\n",
        "    Returns a boolean mask of the peaks (i.e. 1 when\n",
        "    the pixel's value is the neighborhood maximum, 0 otherwise)\n",
        "    \"\"\"\n",
        "\n",
        "    # define an 8-connected neighborhood\n",
        "    neighborhood = generate_binary_structure(2,2)\n",
        "\n",
        "    #apply the local maximum filter; all pixel of maximal value \n",
        "    #in their neighborhood are set to 1\n",
        "    local_max = maximum_filter(image, footprint=neighborhood)==image\n",
        "    #local_max is a mask that contains the peaks we are \n",
        "    #looking for, but also the background.\n",
        "    #In order to isolate the peaks we must remove the background from the mask.\n",
        "\n",
        "    #we create the mask of the background\n",
        "    background = (image==0)\n",
        "\n",
        "    #a little technicality: we must erode the background in order to \n",
        "    #successfully subtract it form local_max, otherwise a line will \n",
        "    #appear along the background border (artifact of the local maximum filter)\n",
        "    eroded_background = binary_erosion(background, structure=neighborhood, border_value=1)\n",
        "\n",
        "    #we obtain the final mask, containing only peaks, \n",
        "    #by removing the background from the local_max mask (xor operation)\n",
        "    detected_peaks = local_max ^ eroded_background\n",
        "    detected_peaks=np.where(detected_peaks==True,1,0)\n",
        "\n",
        "    return detected_peaks\n",
        "\n",
        "\n",
        "#applying the detection and plotting results\n",
        "for i, paw in enumerate(paws):\n",
        "    detected_peaks = detect_peaks(paw)\n",
        "    pp.subplot(1,2,(2*i+1))\n",
        "    pp.imshow(paw)\n",
        "    pp.subplot(1,2,(2*i+2) )\n",
        "    pp.imshow(detected_peaks)\n",
        "\n",
        "pp.show()"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPVdL9UXO-0h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "6c6deda3-c831-4408-864f-33924bf39c46"
      },
      "source": [
        "def left_shifting(matrix,detected_peak):\n",
        "  #input은 detected_peak가 들어와야한다.\n",
        "  dots=[]\n",
        "  for j in range(len(detected_peak)):\n",
        "    pos=[]\n",
        "    for i in range(len(detected_peak[0])):#for 문의 순서를 이렇게 지정해야 Handle이 가능하다.\n",
        "      if(detected_peak[i][j]==1):\n",
        "        if(j%2!=0 and j%3!=0):\n",
        "          j=j-1\n",
        "        if(len(pos)==0):\n",
        "          pos=[i,j]\n",
        "        else:\n",
        "          if (matrix[pos[0]][pos[1]]<matrix[i][j]):\n",
        "            pos=[i,j]\n",
        "    if(len(pos)!=0):\n",
        "      dots.append(pos)\n",
        "  dots_with_length=[]\n",
        "  for position in dots:\n",
        "    length_val=0\n",
        "    while True:\n",
        "      if(position[1]+length_val>23):\n",
        "        break\n",
        "      elif(matrix[position[0]][position[1]+length_val]!=0):\n",
        "        dots_with_length.append([position[0],position[1]+length_val])\n",
        "      else:\n",
        "        break\n",
        "      length_val+=1\n",
        "  result=np.zeros_like(matrix)\n",
        "  for position in dots_with_length:\n",
        "    result[position[0]][position[1]]=1\n",
        "  return result\n",
        "\n",
        "plt.imshow(left_shifting(matrix_cleaner(H),detected_peaks))"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2de9150c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}